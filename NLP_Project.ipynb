{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVibbsn19Kk8",
        "outputId": "d05b2686-e2a4-4a4a-cd33-9bc942d9a47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.28.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Collecting trl\n",
            "  Downloading trl-0.8.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.38.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.28.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.18.0)\n",
            "Collecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.2)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl) (1.16.0)\n",
            "Installing collected packages: shtab, tyro, trl\n",
            "Successfully installed shtab-1.7.1 trl-0.8.1 tyro-0.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install datasets\n",
        "!pip install huggingface_hub\n",
        "!pip install peft\n",
        "!pip install trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Hd4cgO827t",
        "outputId": "74221893-7484-4da4-da8e-7bad65774595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_path = \"./data.csv\"\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    raise Exception(\"File not found : {}\".format(data_path))\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df.head()\n",
        "\n",
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import the libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPVgcSjr9InZ",
        "outputId": "bea62b95-d2fc-460f-f2c2-b6845fac84d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "from peft import LoraConfig, PeftModelForCausalLM\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from datasets import Dataset\n",
        "import json\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from transformers import AutoModelForSequenceClassification, GemmaForSequenceClassification\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import f1_score\n",
        "import json\n",
        "\n",
        "\n",
        "login(\"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set the CONFIG Files\n",
        "- Change the MODEL_ID, BNB Config based on the input model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "    MODEL_ID = \"google/gemma-2b-it\"\n",
        "    # MODEL_ID = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "    BNB_CONFIG = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        # bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    DEVICE_MAP = \"auto\"\n",
        "    DEVICE = \"cuda:0\"\n",
        "    ADD_EOS_TOKEN = True\n",
        "    PADDING_SIDE = \"right\"\n",
        "\n",
        "    LORA_CONFIG = LoraConfig(\n",
        "        lora_alpha = 16,\n",
        "        lora_dropout=0.1,\n",
        "        r=16,\n",
        "        task_type='CAUSAL_LM'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Init model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "19cf4616f5f547d9861d98f7350034ec",
            "a7a15f160a4c44babe366d740d198cb4",
            "7e639766ac784badbf5b66d87eab9b82",
            "d5ef7839648048b0b30755a289d313e5",
            "3718bbeec3544a8aab6103ac0c0f3247",
            "d9e5c0b616004bc39bb34550854d8ff3",
            "935d8e7e02444b539464c98d2d8bc534",
            "c59eeca241444813846b4c7e14216495",
            "ad26c5c13ecf46628f26856edb69c93b",
            "06c6da7350904d8c9685430457a5547b",
            "bcb6f5d5775841069c63f4220e327db4"
          ]
        },
        "id": "3vhWTtUJAA2b",
        "outputId": "13309bc7-86f5-418d-b8e8-08148ca6f5eb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19cf4616f5f547d9861d98f7350034ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(CONFIG.MODEL_ID, quantization_config=CONFIG.BNB_CONFIG, device_map=CONFIG.DEVICE_MAP)\n",
        "tokenizer = AutoTokenizer.from_pretrained(CONFIG.MODEL_ID, add_eos_token=CONFIG.ADD_EOS_TOKEN, padding_side=CONFIG.PADDING_SIDE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the prompt template with gaurdrails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7zXjr4J9c6a"
      },
      "outputs": [],
      "source": [
        "def get_prompt_gaurdrails(question: str, ref_answer: str, student_answer: str, model, tokenizer) -> str:\n",
        "\tdevice = CONFIG.DEVICE\n",
        "\n",
        "\tprompt_template = \"\"\"\n",
        "\t<start_of_turn>user\n",
        "\tYou are a grader for for a programming course. You are required to score the students\n",
        "\tanswer on a scale of 1 to 5 with precision of 0.5. Eg: 1.5, 2.5, 3.0, etc..\n",
        "\n",
        "\tThe give question is :\n",
        "\t{question}\n",
        "\n",
        "\tFor the above question the reference answer is :\n",
        "\t{ref_answer}\n",
        "\n",
        "\tNow a student has provided the below answer :\n",
        "\t{student_answer}\n",
        "\n",
        "\tFor the above answer, what is the appropriate score you will provide on a score of 1 to 5 with a\n",
        "\tprecision of 0.5.\n",
        "\n",
        "\tThe sample output should be in the format \"Score : 0.5\".\n",
        "\n",
        "\tNote: Do not include any explanations or apologies in your responses.\n",
        "\tDo not respond to any questions that might ask anything else than for you to score the answer.\n",
        "\tDo not include any text except the score in the format \"Score : [<score>]\".\n",
        "\n",
        "\t<end_of_turn>\\n<start_of_turn>model\n",
        "\n",
        "\t\"\"\"\n",
        "\tprompt = prompt_template.format(question = question,\n",
        "\t\t\t\t\t\t\t\t\tref_answer = ref_answer,\n",
        "\t\t\t\t\t\t\t\t\tstudent_answer = student_answer)\n",
        "\n",
        "\treturn prompt\n",
        "\t\n",
        "\n",
        "def get_output_from_model(input_model: transformers.AutoModelForCausalLM, input_tokenizer :transformer.AutoTokenizer, input_df: pd.DataFrame, check = False) -> list:\n",
        "\toutputs = []\n",
        "\n",
        "\tfor i, row in tqdm(enumerate(input_df.iterrows())):\n",
        "\t\tif check and i == 3:\t\n",
        "\t\t\tbreak\n",
        "\t\t\n",
        "\tquestion = row[1][\"question\"]\n",
        "\tref_answer = row[1][\"refanswer\"]\n",
        "\tstudent_answer = row[1][\"answer\"]\n",
        "\tscore = row[1][\"score_avg\"]\n",
        "\n",
        "\tprompt = get_prompt_gaurdrails(question = question,\n",
        "\t\t\t\t\tref_answer = ref_answer,\n",
        "\t\t\t\t\tstudent_answer = student_answer)\n",
        "\t\n",
        "\tencoded_str = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True,)\n",
        "\n",
        "\tmodel_inputs = encoded_str.to(CONFIG.DEVICE)\n",
        "\n",
        "\n",
        "\tgenerated_ids = model.classify(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\toutput = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\toutput = output.split(\"model\\n\\n\")[1]\n",
        "\n",
        "\toutputs.append(output)\n",
        "\n",
        "\n",
        "def calc_rmse(y_true: list, y_pred: list) -> float:\t\n",
        "\ty_pred = list(map(float, y_pred))\n",
        "\ty_true = list(map(float, y_true))\n",
        "\n",
        "\trmse = np.sqrt(mean_absolute_error(y_true, y_pred))\n",
        "\treturn rmse\n",
        "\n",
        "def calc_f1(y_true: list, y_pred: list) -> float:\t\n",
        "\ty_pred = list(map(float, y_pred))\n",
        "\ty_true = list(map(float, y_true))\n",
        "\n",
        "\tf1 = f1_score(y_true, y_pred)\n",
        "\treturn f1\n",
        "\t\n",
        "\n",
        "def get_cleaned_outputs(outputs):\n",
        "    _out = []\n",
        "\n",
        "    for i in range(len(outputs)):\n",
        "        _out.append(outputs[i].split(\"Score : \")[-1].split(\"\\n\")[0])\n",
        "\t\t\n",
        "    return _out\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split the data into train and test df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split the data into train and test set\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"score_avg\"])\n",
        "print(\"train shape : \", df_train.shape)\n",
        "print(\"test shape : \", df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute the below code to make sure the model is working properly and get a sample output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyyTcIAl-TD7",
        "outputId": "7708ca40-713b-4d9f-962c-b015d8341f2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  user\n",
            "  You are a grader for for a programming course. You are required to score the students\n",
            "  answer on a scale of 1 to 5 with precision of 0.5. Eg: 1.5, 2.5, 3.0, etc..\n",
            "\n",
            "  The give question is : \n",
            "  What is the role of a prototype program in problem solving?\n",
            "\n",
            "  For the above question the reference answer is : \n",
            "  To simulate the behaviour of portions of the desired software product.\n",
            "\n",
            "  Now a student has provided the below answer : \n",
            "  High risk problems are address in the prototype program to make sure that the program is feasible.  A prototype may also be used to show a company that the software can be possibly programmed.  \n",
            "\n",
            "  For the above answer, what is the appropriate score you will provide on a score of 1 to 5 with a\n",
            "  precision of 0.5.\n",
            "\n",
            "  The sample output should be in the format \"Score : 0.5\".\n",
            "\n",
            "  Note: Do not include any explanations or apologies in your responses.\n",
            "  Do not respond to any questions that might ask anything else than for you to score the answer.\n",
            "  Do not include any text except the score in the format \"Score : [<score>]\".\n",
            "\n",
            "  \n",
            "model\n",
            "\n",
            "   Score : 0.5\n"
          ]
        }
      ],
      "source": [
        "question = \"What is the role of a prototype program in problem solving?\"\n",
        "ref_answer = \"To simulate the behaviour of portions of the desired software product.\"\n",
        "student_answer = \"High risk problems are address in the prototype program to make sure that the program is feasible.  A prototype may also be used to show a company that the software can be possibly programmed.  \"\n",
        "score = \"3.5\"\n",
        "\n",
        "result = get_prompt_gaurdrails(question = question,\n",
        "                        ref_answer = ref_answer,\n",
        "                        student_answer = student_answer,\n",
        "                        model = model,\n",
        "                        tokenizer = tokenizer)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the below code to generate the outputs from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_pic_2ks_7z7",
        "outputId": "8ee57a1f-ed55-4819-da14-6ebd46124550"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "1it [00:01,  1.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "2it [00:02,  1.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "3it [00:02,  1.03it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "4it [00:03,  1.03it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "5it [00:04,  1.03it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "6it [00:05,  1.01it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "7it [00:06,  1.04it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "8it [00:07,  1.06it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "9it [00:08,  1.04it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "10it [00:09,  1.05it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "11it [00:10,  1.03it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "12it [00:11,  1.03it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "13it [00:12,  1.02it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "14it [00:13,  1.01it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "15it [00:14,  1.00it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "16it [00:15,  1.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "17it [00:16,  1.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "18it [00:17,  1.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "19it [00:18,  1.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "20it [00:19,  1.01it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "21it [00:20,  1.03it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "22it [00:21,  1.01it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "23it [00:22,  1.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "24it [00:23,  1.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "25it [00:24,  1.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "26it [00:25,  1.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "27it [00:26,  1.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "28it [00:28,  1.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "29it [00:29,  1.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "30it [00:30,  1.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "31it [00:30,  1.00it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "32it [00:32,  1.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "33it [00:33,  1.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "34it [00:34,  1.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "35it [00:35,  1.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "36it [00:36,  1.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "37it [00:39,  1.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "38it [00:41,  1.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "39it [00:42,  1.47s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "40it [00:43,  1.34s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "41it [00:44,  1.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "42it [00:45,  1.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "43it [00:46,  1.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "44it [00:47,  1.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "45it [00:48,  1.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "46it [00:49,  1.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "47it [00:50,  1.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "48it [00:51,  1.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "49it [00:52,  1.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "50it [00:53,  1.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "51it [00:55,  1.40s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "52it [00:56,  1.26s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "53it [00:57,  1.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "54it [01:00,  1.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "55it [01:01,  1.48s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "56it [01:02,  1.31s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "57it [01:03,  1.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "58it [01:04,  1.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "59it [01:05,  1.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "60it [01:06,  1.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "61it [01:08,  1.53s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "62it [01:09,  1.38s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "63it [01:10,  1.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "64it [01:11,  1.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "65it [01:12,  1.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "66it [01:13,  1.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "67it [01:14,  1.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "67it [01:17,  1.15s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-f046f318c3a9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score_avg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     output = get_completion(question = question,\n\u001b[0m\u001b[1;32m     13\u001b[0m                         \u001b[0mref_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mstudent_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-691df6cb0807>\u001b[0m in \u001b[0;36mget_completion\u001b[0;34m(question, ref_answer, student_answer, model, tokenizer)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;31m# decoded = tokenizer.batch_decode(generated_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1593\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2696\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2697\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1074\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m                 )\n\u001b[1;32m    913\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    915\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# Reference: https://github.com/pytorch/pytorch/issues/112577.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcausal_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "outputs = get_output_from_model(model, tokenizer, df_train)\n",
        "\n",
        "# add the outputs to the df_train dataframe for easy processing\n",
        "df_train[\"model_output\"][:len(outputs)] = outputs\n",
        "# clean the output to remove the string associated with them\n",
        "df_train[\"model_output\"] = get_cleaned_outputs(df_train[\"model_output\"].tolist())\n",
        "\n",
        "# calculate the rmse square\n",
        "calc_rmse(df_train[\"score_avg\"].tolist(), df_train[\"model_output\"].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlUt7QYSC5Hs"
      },
      "source": [
        "# Finetune the model using Qlora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert the data into prompts and store it as a json object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=\"score_avg\")\n",
        "y = df[\"score_avg\"]\n",
        "\n",
        "\n",
        "# create a new set of train and test data\n",
        "train_df, test_df = train_test_split(df, random_state=42, test_size=0.2)\n",
        "\n",
        "print(\"len of x_train : \", len(train_df))\n",
        "print(\"len of x_test : \", len(test_df))\n",
        "\n",
        "\n",
        "def convert_txt_to_qlora_dict(input_df : pd.DataFrame):\n",
        "\n",
        "  __template_assistant = \"\"\"\n",
        "  Score : {score}\n",
        "  \"\"\"\n",
        "\n",
        "  json_dict = {\n",
        "      \"messages\" : []\n",
        "  }\n",
        "\n",
        "  for rowind, row in tqdm(input_df.iterrows()):\n",
        "    user_prompt = get_prompt_gaurdrails(question = row[\"question\"],\n",
        "\t\t\t\t\tref_answer = row[\"refanswer\"],\n",
        "\t\t\t\t\tstudent_answer = row[\"answer\"])\n",
        "    \n",
        "    assistant_prompt = __template_assistant.format(score = row[\"score_avg\"])\n",
        "\n",
        "    ls = [\n",
        "      {\n",
        "        \"role\" : \"user\",\n",
        "        \"content\" : user_prompt\n",
        "      },\n",
        "      {\n",
        "        \"role\" : \"assistant\",\n",
        "        \"content\" : assistant_prompt\n",
        "      }\n",
        "    ]\n",
        "\n",
        "    json_dict[\"messages\"].append(ls)\n",
        "\n",
        "  return json_dict\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the dict version of the prompts\n",
        "train_json = convert_txt_to_qlora_dict(train_df)\n",
        "test_json = convert_txt_to_qlora_dict(test_df)\n",
        "\n",
        "# Specify the file path where you want to save the JSON file\n",
        "train_file_path = \"EN-train_chatml.json\"\n",
        "test_file_path = \"EN-val_chatml.json\"\n",
        "\n",
        "# Save the dictionary as a JSON file\n",
        "with open(train_file_path, \"w\") as json_file:\n",
        "    json.dump(train_json, json_file)\n",
        "\n",
        "with open(test_file_path, \"w\") as json_file:\n",
        "    json.dump(train_json, json_file)\n",
        "\n",
        "# load the file again\n",
        "save_path = \"./\"\n",
        "dataset_train_name = 'EN-train'\n",
        "dataset_val_name = 'EN-val'\n",
        "\n",
        "file_name_train_chatml = f\"{dataset_train_name}_chatml.json\"\n",
        "file_name_val_chatml = f\"{dataset_val_name}_chatml.json\"\n",
        "\n",
        "with open(save_path + file_name_train_chatml, 'r') as f:\n",
        "  dataset_train = Dataset.from_dict(json.load(f))\n",
        "\n",
        "with open(save_path + file_name_val_chatml, 'r') as f:\n",
        "  dataset_val = Dataset.from_dict(json.load(f))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "a3dd105380ae4c7399498f026234190e",
            "741bb1694ea14ad78659b621e0f096ac",
            "c2c036802e164c198368244d386835e3",
            "c06e2e7ac69e4404bfc8bd8f681a1bba",
            "0b209933a5d94ff9a92c2f944a4420e2",
            "265dffeb6f2e46cbab16d7ce50ff730b",
            "861779d429534021952d339c814b483b",
            "60687234ffb4449fbaf589d35f2120b8",
            "f94d411368a147cd8753b8d3e0c47d1d",
            "c10490f0d26e4764bc92d0b5627b2d98",
            "ed4b4c1d375e42809e9b2416b6688e60"
          ]
        },
        "id": "TK3MJWecC9E3",
        "outputId": "f0b63f1b-12d6-49d5-c66e-b3b6c3239146"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3dd105380ae4c7399498f026234190e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lora_model = AutoModelForCausalLM.from_pretrained(CONFIG.MODEL_ID, quantization_config=CONFIG.BNB_CONFIG, device_map=CONFIG.DEVICE_MAP)\n",
        "lora_tokenizer = AutoTokenizer.from_pretrained(CONFIG.MODEL_ID, padding_side=CONFIG.PADDING_SIDE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Qlora params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632,
          "referenced_widgets": [
            "bb4348e548a64ad785e2da9f4c0fbff6",
            "29ce0db2bd6c45c1818ed285ccc50dea",
            "c9c71f646f854e58ae1828a69ddf79c8",
            "b4a8cf5b6f2043bfadd4a1aeef11f084",
            "1f92ea54c3a943daae5deee576d822e4",
            "dea14849cf2d447290ba7097b2568845",
            "ebcb2b1cb1ab4d198e2c9896ddf93e39",
            "2683bb7995cd41b6904209424e706c38",
            "7f5b4e542cb44d6db12a5a0ed4f3e920",
            "fd173dc720a742488fe364d525da4d8c",
            "37b39db11af347dba47b8802cba3c11d",
            "3f2b166470db4eeabac98ad7db8853b0",
            "932855a1c23147fc823b5c65bff1acd7",
            "6199538a818741e58e5fb557e41b5893",
            "b2836276208a4629b61427394e93839e",
            "149e08f1c69c49ba98535010d8470894",
            "b34341b354274c55a813d8f043144124",
            "ebee9b8f3aaf4eefa1f3b9be0013bfe4",
            "9911003026d9451681d52869e8af5320",
            "c25bd12e7a8948c0ab916e9efda39ad1",
            "2e6c5c39aaf84976a1247e31e83c4999",
            "a2a9dabcbcde43659ab648d4bde6fe59"
          ]
        },
        "id": "dgaFERyPDev7",
        "outputId": "a0b2ce93-f5ec-4d8c-f39a-2405a0b8897f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:256: UserWarning: You passed a `neftune_noise_alpha` argument to the SFTTrainer, the value you passed will override the one in the `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb4348e548a64ad785e2da9f4c0fbff6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4735 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f2b166470db4eeabac98ad7db8853b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4735 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='95' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 95/100 57:25 < 03:05, 0.03 it/s, Epoch 0.64/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.142000</td>\n",
              "      <td>4.889306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.431800</td>\n",
              "      <td>3.713480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.255400</td>\n",
              "      <td>2.846437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.523800</td>\n",
              "      <td>2.165644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 1:09:37, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.142000</td>\n",
              "      <td>4.889306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.431800</td>\n",
              "      <td>3.713480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.255400</td>\n",
              "      <td>2.846437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.523800</td>\n",
              "      <td>2.165644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.941900</td>\n",
              "      <td>1.734175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=3.4589868545532227, metrics={'train_runtime': 4188.6957, 'train_samples_per_second': 0.764, 'train_steps_per_second': 0.024, 'total_flos': 5568902666575872.0, 'train_loss': 3.4589868545532227, 'epoch': 0.68})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir = \"./output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    logging_strategy=\"steps\",\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    logging_steps=20,\n",
        "    eval_steps=20,\n",
        "    save_steps=20,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=16,\n",
        "    eval_accumulation_steps=16,\n",
        "    num_train_epochs=1,\n",
        "    fp16=True,\n",
        "    group_by_length = True,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    max_steps = 100\n",
        ")\n",
        "trainer = SFTTrainer(\n",
        "    model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_val,\n",
        "    peft_config=CONFIG.LORA_CONFIG,\n",
        "    neftune_noise_alpha=5,\n",
        "    max_seq_length=500,\n",
        "    args = training_arguments\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6t5inlKwD_QK"
      },
      "outputs": [],
      "source": [
        "model_save_name = \"/output\"\n",
        "\n",
        "trainer.model.save_pretrained(\"/output\")\n",
        "finetuned_model = PeftModelForCausalLM.from_pretrained(model=model, model_id=\"/output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sample Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TLMwxr_rGFXr"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "    {\n",
        "        'role':'user',\n",
        "        'content':'Who is Francesco Lelli?',\n",
        "    }\n",
        "]\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n  The give question is : \\n    What are the elements typically included in a class definition\\n\\n    For the above question the reference answer is : \\n    Function members and data members\\n\\n    Now a student has provided the below answer : \\n    the functions and variables used when the object is defined for the class\\n\\n    For the above answer, what is the appropriate score you will provide on a score of 1 to 5 with a\\n    precision of 0.5.\\n    \"\n",
        "        }\n",
        "]\n",
        "\n",
        "input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# print(input_ids)\n",
        "outputs_finetuned = finetuned_model.generate(input_ids=input_ids, max_new_tokens=1024, do_sample=False)\n",
        "outputs = model.generate(input_ids=input_ids, max_new_tokens=1024, do_sample=False)\n",
        "\n",
        "print(\"finetuned: \" + tokenizer.decode(outputs_finetuned[0]).split('<start_of_turn>model\\n')[-1])\n",
        "print(\"normal   : \" + tokenizer.decode(outputs[0]).split('<start_of_turn>model\\n')[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Zip the folder for easy download from colab to local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oax8d5pWWVqM",
        "outputId": "38eede29-3e56-4283-89cb-32e7e60c3e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: output/ (stored 0%)\n",
            "  adding: output/checkpoint-80/ (stored 0%)\n",
            "  adding: output/checkpoint-80/rng_state.pth (deflated 25%)\n",
            "  adding: output/checkpoint-80/trainer_state.json (deflated 70%)\n",
            "  adding: output/checkpoint-80/adapter_model.safetensors (deflated 8%)\n",
            "  adding: output/checkpoint-80/README.md (deflated 66%)\n",
            "  adding: output/checkpoint-80/optimizer.pt (deflated 7%)\n",
            "  adding: output/checkpoint-80/adapter_config.json (deflated 52%)\n",
            "  adding: output/checkpoint-80/tokenizer_config.json (deflated 72%)\n",
            "  adding: output/checkpoint-80/special_tokens_map.json (deflated 76%)\n",
            "  adding: output/checkpoint-80/training_args.bin (deflated 51%)\n",
            "  adding: output/checkpoint-80/scheduler.pt (deflated 58%)\n",
            "  adding: output/checkpoint-80/tokenizer.model (deflated 51%)\n",
            "  adding: output/checkpoint-80/tokenizer.json (deflated 72%)\n",
            "  adding: output/checkpoint-60/ (stored 0%)\n",
            "  adding: output/checkpoint-60/rng_state.pth (deflated 25%)\n",
            "  adding: output/checkpoint-60/trainer_state.json (deflated 67%)\n",
            "  adding: output/checkpoint-60/adapter_model.safetensors (deflated 8%)\n",
            "  adding: output/checkpoint-60/README.md (deflated 66%)\n",
            "  adding: output/checkpoint-60/optimizer.pt (deflated 7%)\n",
            "  adding: output/checkpoint-60/adapter_config.json (deflated 52%)\n",
            "  adding: output/checkpoint-60/tokenizer_config.json (deflated 72%)\n",
            "  adding: output/checkpoint-60/special_tokens_map.json (deflated 76%)\n",
            "  adding: output/checkpoint-60/training_args.bin (deflated 51%)\n",
            "  adding: output/checkpoint-60/scheduler.pt (deflated 58%)\n",
            "  adding: output/checkpoint-60/tokenizer.model (deflated 51%)\n",
            "  adding: output/checkpoint-60/tokenizer.json (deflated 72%)\n",
            "  adding: output/checkpoint-100/ (stored 0%)\n",
            "  adding: output/checkpoint-100/rng_state.pth (deflated 25%)\n",
            "  adding: output/checkpoint-100/trainer_state.json (deflated 72%)\n",
            "  adding: output/checkpoint-100/adapter_model.safetensors (deflated 8%)\n",
            "  adding: output/checkpoint-100/README.md (deflated 66%)\n",
            "  adding: output/checkpoint-100/optimizer.pt (deflated 8%)\n",
            "  adding: output/checkpoint-100/adapter_config.json (deflated 52%)\n",
            "  adding: output/checkpoint-100/tokenizer_config.json (deflated 72%)\n",
            "  adding: output/checkpoint-100/special_tokens_map.json (deflated 76%)\n",
            "  adding: output/checkpoint-100/training_args.bin (deflated 51%)\n",
            "  adding: output/checkpoint-100/scheduler.pt (deflated 58%)\n",
            "  adding: output/checkpoint-100/tokenizer.model (deflated 51%)\n",
            "  adding: output/checkpoint-100/tokenizer.json (deflated 72%)\n",
            "  adding: output/runs/ (stored 0%)\n",
            "  adding: output/runs/Apr02_23-13-39_79eeb900c4ee/ (stored 0%)\n",
            "  adding: output/runs/Apr02_23-13-39_79eeb900c4ee/events.out.tfevents.1712099622.79eeb900c4ee.4761.0 (deflated 61%)\n",
            "  adding: output/checkpoint-20/ (stored 0%)\n",
            "  adding: output/checkpoint-20/rng_state.pth (deflated 25%)\n",
            "  adding: output/checkpoint-20/trainer_state.json (deflated 55%)\n",
            "  adding: output/checkpoint-20/adapter_model.safetensors (deflated 9%)\n",
            "  adding: output/checkpoint-20/README.md (deflated 66%)\n",
            "  adding: output/checkpoint-20/optimizer.pt (deflated 7%)\n",
            "  adding: output/checkpoint-20/adapter_config.json (deflated 52%)\n",
            "  adding: output/checkpoint-20/tokenizer_config.json (deflated 72%)\n",
            "  adding: output/checkpoint-20/special_tokens_map.json (deflated 76%)\n",
            "  adding: output/checkpoint-20/training_args.bin (deflated 51%)\n",
            "  adding: output/checkpoint-20/scheduler.pt (deflated 58%)\n",
            "  adding: output/checkpoint-20/tokenizer.model (deflated 51%)\n",
            "  adding: output/checkpoint-20/tokenizer.json (deflated 72%)\n",
            "  adding: output/checkpoint-40/ (stored 0%)\n",
            "  adding: output/checkpoint-40/rng_state.pth (deflated 25%)\n",
            "  adding: output/checkpoint-40/trainer_state.json (deflated 63%)\n",
            "  adding: output/checkpoint-40/adapter_model.safetensors (deflated 8%)\n",
            "  adding: output/checkpoint-40/README.md (deflated 66%)\n",
            "  adding: output/checkpoint-40/optimizer.pt (deflated 7%)\n",
            "  adding: output/checkpoint-40/adapter_config.json (deflated 52%)\n",
            "  adding: output/checkpoint-40/tokenizer_config.json (deflated 72%)\n",
            "  adding: output/checkpoint-40/special_tokens_map.json (deflated 76%)\n",
            "  adding: output/checkpoint-40/training_args.bin (deflated 51%)\n",
            "  adding: output/checkpoint-40/scheduler.pt (deflated 58%)\n",
            "  adding: output/checkpoint-40/tokenizer.model (deflated 51%)\n",
            "  adding: output/checkpoint-40/tokenizer.json (deflated 72%)\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!zip -r ./output.zip ./output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH0528oQb868"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mJQRsG9qcIy3"
      },
      "outputs": [],
      "source": [
        "def get_output_from_model_using_prompt(prompt : str, model, tokenizer, finetuned = False) -> str:\n",
        "\tdevice = CONFIG.DEVICE\n",
        "\n",
        "\tencodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True,)\n",
        "\n",
        "\tmodel_inputs = encodeds.to(device)\n",
        "\n",
        "\tgenerated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\tdecoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "\treturn (decoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "qv5j8BhsbWNE",
        "outputId": "f75ec91d-1230-412a-8281-f0d35d4e681e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1215it [56:11,  2.77s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c80415d0d196>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                         tokenizer = tokenizer)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     output_model2 = get_completion(content = user_content,\n\u001b[0m\u001b[1;32m     20\u001b[0m                         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         tokenizer = tokenizer)\n",
            "\u001b[0;32m<ipython-input-19-a888737f1143>\u001b[0m in \u001b[0;36mget_completion\u001b[0;34m(content, model, tokenizer, finetuned)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0;31m# decoded = tokenizer.batch_decode(generated_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1593\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2696\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2697\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1074\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m                 )\n\u001b[1;32m    913\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    915\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_rotary_pos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mpast_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"past_key_value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0msin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsqueeze_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mq_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrotate_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mk_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrotate_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# Copied from transformers.models.llama.modeling_llama.rotate_half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrotate_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;34m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "outputs_finetuned = []\n",
        "outputs_model = []\n",
        "actual_outputs = []\n",
        "\n",
        "for i, row in tqdm(enumerate(dataset_val[\"messages\"])):\n",
        "    # if i == :\n",
        "    #   break\n",
        "\n",
        "    actual_val = float(row[1][\"content\"].split(\": \")[-1].split(\"\\n\")[0])\n",
        "    actual_outputs.append(actual_val)\n",
        "\n",
        "    user_prompt = row[0][\"content\"]\n",
        "\n",
        "    output_finetuned = get_output_from_model_using_prompt(prompt = user_prompt,\n",
        "                        model = model,\n",
        "                        tokenizer = tokenizer)\n",
        "\n",
        "    output_model = get_output_from_model_using_prompt(prompt = user_prompt,\n",
        "                        model = model,\n",
        "                        tokenizer = tokenizer)\n",
        "\n",
        "    output_finetuned = output_finetuned.split(\"model\\n\\n\")[1].split(\"\\n\")[0]\n",
        "    output_model = output_model.split(\"model\\n\\n\")[1].split(\"\\n\")[0]\n",
        "\n",
        "    try:\n",
        "        output_finetuned = float(output_finetuned.split(\": \")[-1].split(\" \")[0])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        output_model = float(output_model.split(\": \")[-1].split(\" \")[0])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    outputs_finetuned.append(output_finetuned)\n",
        "    outputs_model.append(output_model)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wb7k1fZd0md",
        "outputId": "9646579b-1abc-4696-bebd-b82ff2846c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.0, 5.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.5, 3.0, 3.0, 4.5, 3.5, 2.0, 5.0, 4.5, 5.0, 5.0, 2.5, 4.5, 1.5, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 4.0, 5.0, 5.0, 2.0, 4.5, 3.5, 4.0, 1.0, 3.0, 3.5, 4.5, 4.0, 5.0, 3.0, 2.5, 5.0, 5.0, 4.0, 5.0, 4.5, 2.5, 5.0, 4.0, 3.5, 1.5, 5.0, 3.5, 1.5, 3.0, 5.0, 5.0, 3.0, 2.0, 4.0, 5.0, 5.0, 4.0, 4.5, 4.0, 4.5, 5.0, 5.0, 4.5, 3.0, 4.0, 4.5, 0.0, 4.0, 3.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.5, 2.5, 3.0, 2.5, 3.5, 3.0, 5.0, 5.0, 4.5, 3.5, 5.0, 5.0, 5.0, 4.5, 3.5, 5.0, 4.0, 4.0, 4.5, 1.5, 5.0, 5.0, 2.0, 5.0, 2.0, 4.5, 5.0, 2.0, 5.0, 4.5, 4.0, 3.5, 2.0, 1.5, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 3.5, 4.0, 5.0, 4.5, 4.0, 4.5, 5.0, 1.0, 2.5, 3.0, 4.5, 3.5, 5.0, 4.5, 2.5, 2.0, 5.0, 3.5, 5.0, 4.0, 4.0, 5.0, 1.5, 3.5, 4.0, 5.0, 3.0, 4.5, 5.0, 5.0, 4.5, 3.5, 5.0, 5.0, 4.5, 2.5, 5.0, 5.0, 5.0, 5.0, 3.0, 2.5, 5.0, 1.0, 3.5, 4.5, 5.0, 5.0, 5.0, 5.0, 4.5, 1.5, 5.0, 2.0, 5.0, 3.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 0.0, 4.5, 5.0, 4.0, 2.5, 5.0, 3.5, 5.0, 4.5, 2.0, 5.0, 5.0, 4.5, 3.5, 2.5, 3.5, 4.5, 4.0, 4.5, 1.0, 5.0, 5.0, 3.5, 5.0, 5.0, 5.0, 4.0, 5.0, 4.5, 5.0, 5.0, 3.5, 4.0, 4.5, 4.5, 5.0, 3.5, 5.0, 4.0, 3.0, 5.0, 3.5, 5.0, 3.0, 5.0, 5.0, 5.0, 0.0, 5.0, 0.0, 5.0, 3.5, 4.5, 5.0, 4.5, 4.5, 5.0, 3.0, 4.0, 5.0, 2.5, 3.5, 3.0, 4.0, 4.0, 5.0, 1.0, 5.0, 2.5, 4.0, 3.5, 4.0, 1.5, 5.0, 5.0, 3.5, 5.0, 3.5, 5.0, 5.0, 5.0, 2.5, 4.5, 5.0, 5.0, 4.0, 4.0, 4.5, 5.0, 5.0, 2.0, 5.0, 5.0, 4.5, 2.0, 1.0, 2.0, 4.0, 5.0, 4.0, 5.0, 4.0, 2.5, 4.5, 5.0, 3.0, 4.5, 5.0, 4.0, 4.5, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 3.5, 3.5, 4.5, 5.0, 5.0, 4.5, 4.5, 5.0, 5.0, 5.0, 4.5, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.5, 3.0, 4.0, 3.5, 5.0, 5.0, 3.5, 4.0, 4.5, 2.5, 5.0, 2.0, 5.0, 5.0, 2.5, 5.0, 4.0, 3.5, 5.0, 5.0, 3.5, 5.0, 5.0, 3.5, 4.0, 3.0, 4.5, 3.5, 2.0, 5.0, 5.0, 4.0, 4.0, 5.0, 3.5, 5.0, 5.0, 2.5, 4.0, 3.0, 3.0, 5.0, 4.0, 5.0, 2.0, 5.0, 5.0, 5.0, 5.0, 4.5, 2.0, 5.0, 4.0, 2.0, 3.5, 5.0, 5.0, 5.0, 2.5, 4.0, 5.0, 4.0, 4.5, 3.5, 4.5, 4.5, 4.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 4.5, 5.0, 4.5, 5.0, 5.0, 5.0, 4.5, 3.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.5, 5.0, 5.0, 5.0, 4.0, 2.5, 3.0, 3.5, 3.0, 5.0, 3.5, 5.0, 2.5, 3.0, 5.0, 4.5, 4.0, 3.0, 3.0, 4.5, 4.5, 5.0, 3.0, 3.5, 4.0, 4.0, 4.5, 3.5, 5.0, 2.0, 5.0, 4.0, 3.5, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 3.5, 3.0, 2.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.5, 5.0, 4.0, 1.5, 5.0, 5.0, 4.0, 5.0, 5.0, 4.5, 5.0, 4.0, 5.0, 4.0, 3.5, 2.5, 5.0, 5.0, 2.5, 5.0, 2.5, 5.0, 5.0, 5.0, 5.0, 3.5, 3.5, 4.0, 5.0, 3.0, 5.0, 5.0, 4.5, 5.0, 1.5, 5.0, 3.5, 3.0, 5.0, 5.0, 5.0, 5.0, 1.0, 4.5, 2.5, 3.5, 4.0, 2.0, 5.0, 5.0, 4.0, 5.0, 4.0, 2.0, 4.5, 1.5, 4.5, 5.0, 5.0, 4.5, 1.5, 5.0, 5.0, 5.0, 4.5, 4.5, 4.5, 4.0, 3.0, 3.0, 4.0, 5.0, 2.5, 5.0, 5.0, 5.0, 5.0, 4.0, 3.5, 4.5, 4.0, 4.5, 3.5, 3.0, 5.0, 5.0, 4.0, 2.0, 3.0, 3.5, 4.0, 4.5, 2.5, 5.0, 3.5, 4.0, 4.5, 4.0, 5.0, 3.5, 5.0, 2.5, 4.0, 3.0, 2.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 2.0, 5.0, 4.5, 4.0, 2.5, 3.0, 0.0, 3.5, 4.5, 3.0, 5.0, 5.0, 3.5, 3.5, 2.5, 5.0, 3.0, 4.5, 5.0, 5.0, 5.0, 3.5, 2.5, 5.0, 5.0, 4.0, 5.0, 2.5, 4.5, 4.5, 3.5, 4.5, 4.5, 4.5, 5.0, 2.5, 3.5, 3.5, 4.0, 5.0, 2.5, 5.0, 5.0, 2.5, 5.0, 4.5, 5.0, 5.0, 2.5, 5.0, 4.5, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 2.5, 4.5, 3.5, 5.0, 5.0, 4.5, 5.0, 5.0, 5.0, 4.5, 4.0, 4.5, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0, 4.5, 1.0, 3.0, 5.0, 5.0, 0.0, 4.5, 5.0, 5.0, 5.0, 2.5, 2.5, 3.0, 5.0, 5.0, 4.5, 2.5, 5.0, 2.0, 0.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 4.5, 3.0, 5.0, 3.5, 5.0, 3.0, 5.0, 5.0, 1.5, 5.0, 3.5, 5.0, 5.0, 5.0, 5.0, 2.0, 4.5, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 2.5, 3.0, 3.5, 4.0, 5.0, 5.0, 5.0, 3.0, 4.0, 4.5, 3.0, 4.5, 5.0, 5.0, 2.5, 4.5, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 5.0, 4.5, 4.5, 4.5, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 4.0, 3.0, 4.5, 5.0, 4.0, 5.0, 3.5, 2.5, 4.5, 5.0, 5.0, 4.5, 3.5, 3.5, 5.0, 2.0, 3.5, 5.0, 4.5, 3.5, 2.5, 5.0, 5.0, 2.0, 5.0, 4.5, 2.5, 4.5, 4.0, 5.0, 5.0, 3.0, 5.0, 4.5, 2.5, 3.0, 2.0, 4.0, 2.5, 5.0, 4.0, 3.5, 4.0, 2.5, 4.0, 3.5, 5.0, 4.5, 4.0, 4.0, 4.0, 5.0, 5.0, 3.5, 5.0, 3.5, 4.0, 5.0, 3.0, 5.0, 3.5, 5.0, 1.0, 5.0, 4.5, 5.0, 4.0, 5.0, 3.5, 2.5, 4.0, 1.5, 5.0, 4.5, 5.0, 4.5, 3.0, 5.0, 4.5, 2.5, 2.5, 5.0, 5.0, 5.0, 4.5, 5.0, 2.5, 5.0, 5.0, 5.0, 3.5, 5.0, 5.0, 3.5, 2.0, 5.0, 2.0, 1.5, 4.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 2.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 5.0, 5.0, 4.0, 2.0, 5.0, 2.0, 5.0, 3.5, 5.0, 4.5, 5.0, 5.0, 5.0, 3.5, 5.0, 5.0, 4.0, 2.5, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.5, 4.5, 5.0, 4.5, 5.0, 5.0, 5.0, 4.5, 5.0, 4.5, 5.0, 4.5, 4.5, 2.5, 5.0, 4.0, 5.0, 3.5, 4.0, 2.5, 4.0, 4.0, 4.0, 5.0, 3.0, 4.0, 4.0, 1.0, 3.5, 3.5, 1.0, 5.0, 3.0, 5.0, 4.5, 3.5, 0.0, 4.5, 5.0, 4.5, 3.0, 5.0, 4.5, 3.5, 3.5, 5.0, 4.0, 2.0, 3.5, 4.5, 5.0, 3.5, 5.0, 4.0, 0.0, 3.5, 5.0, 5.0, 5.0, 5.0, 4.0, 2.5, 4.5, 5.0, 5.0, 5.0, 4.5, 1.5, 3.5, 4.0, 5.0, 4.0, 1.5, 4.0, 4.5, 3.5, 2.0, 4.5, 4.5, 3.5, 5.0, 5.0, 4.0, 5.0, 5.0, 2.5, 5.0, 5.0, 2.5, 3.5, 5.0, 4.5, 2.5, 0.5, 5.0, 3.5, 5.0, 4.5, 5.0, 1.0, 5.0, 4.5, 5.0, 2.0, 5.0, 5.0, 4.5, 3.5, 4.5, 3.5, 4.5, 5.0, 5.0, 5.0, 3.0, 0.0, 3.0, 3.0, 5.0, 5.0, 5.0, 0.0, 5.0, 4.0, 5.0, 4.5, 3.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 5.0, 5.0, 1.5, 4.5, 2.0, 3.0, 1.0, 5.0, 4.5, 5.0, 4.5, 5.0, 5.0, 5.0, 5.0, 4.5, 5.0, 4.0, 2.5, 4.0, 3.5, 3.0, 2.0, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 4.0, 5.0, 4.5, 3.5, 2.5, 5.0, 3.5, 5.0, 1.5, 5.0, 4.5, 5.0, 4.5, 3.5, 5.0, 2.5, 3.0, 4.5, 4.5, 0.0, 4.0, 3.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.5, 3.5, 3.0, 5.0, 3.5, 2.0, 5.0, 5.0, 4.0, 3.0, 2.5, 4.5, 2.0, 5.0, 3.0, 4.5, 4.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 1.5, 4.0, 5.0, 5.0, 4.5, 5.0, 4.0, 4.5, 4.0, 2.5, 5.0, 5.0, 5.0, 5.0, 4.5, 2.0, 4.5, 3.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.5, 4.0, 0.0, 5.0, 4.5, 5.0, 5.0, 4.5, 3.0, 5.0, 5.0, 4.5, 5.0, 1.0, 5.0, 2.5, 5.0, 2.5, 2.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 5.0, 3.0, 5.0, 5.0, 5.0, 2.5, 2.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.5, 3.0, 3.5, 5.0, 4.0, 0.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.5, 4.5, 5.0, 5.0, 4.0, 3.5, 4.5, 4.0, 5.0, 4.5, 3.0, 4.5, 2.5, 3.5, 3.5, 3.5, 5.0, 1.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 4.0, 5.0, 4.0, 4.5, 3.0, 5.0, 5.0, 3.5, 5.0, 5.0, 1.0, 5.0, 5.0, 4.0, 5.0, 3.0, 4.0, 5.0, 1.5, 4.0, 5.0, 2.5, 4.0, 5.0, 5.0, 5.0, 4.0, 4.5, 4.0, 3.5, 2.0, 3.0, 5.0, 2.5, 5.0]\n",
            "['  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.0', '  Score : 4.0', '  Score : 3.5', '  Score : 5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5.', '  Score : 3.0', '  Score : 4,0', '  Score : 4.0', '  Score : 3.0', '  Score : 1.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 3.5', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score: 4.5', '  Score : 3.0', '  Score : 4.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.5', '  Score : 2.0', '  Score : 5.0', '  Score : 3.0', '  Score : 4.00', '  Score : 2.5.', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5.', '  Score: 3.0', '  Score : 4.0', '  Score : 2.5.', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5 \\\\<5>.', '  Score : 3.5', '  Score : 5.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.0', '  Score : 2.0.', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 5.00', '  Score : 5.0', '  Score : 4.0', '  Score : 3.0', '  Score : 1.5', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 4.5', '  Score : 2.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score: 3.0', '  Score : 2.5', '  Score: 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score : 4.5', '  Score : 5.0', '  Score : 3.0 Cleaning worst case scenarios from all best cases', '  Score : 3.0', '  Score : 2.5', '  Score: 3.0', '  Score : 3.0', '  Score : 2.5.', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 1.5', '  Score : 3.5', '  Score : 2.5', '  Score : 4.0', '  Score : 4.5', '  Score : 2.5.', '  Score : 2.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 1.5', '  Score : 4.5', '  Score : 4.0', '  Score : 1.5,', '  Score : 3.5', '  Score : 5.0', '  Score : 3.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0,', '  Score : 4.0', '  Score : 5.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 1.5', '  Score : 2.5 Operand, StringBuffer was passed by reference.', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0.', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.00', '  Score : 2.5', '  Score : 2.0', '  Score : 2.0.', '  Score: 4.5', '  Score : 2.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0   ', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.5.', '  Score : 3.0', '  Score : 1.5', '  Score : 2.5.', '  Score : 2.5', '  Score : 4.0', '  Score : 5.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0.', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score: 5.0', '  Score : 3.0', '  Score : 1.5.', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score : 5.0', '  Score : 2.5.', '  Score: 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 4.0', '  Score : 4.0', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 4.5', '  Score : 5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 4.0', '  Score: 3.0', '  Score : 4.5', '  Score : 4.0', '  Score : 2.5.', '  Score : 4.0', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 2.0', '  Score : 4.5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 4.0', '  Score : 4.0 |- Excellent', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.5', '  Score : 2.5', '  Score : 3.0', '  Score : 5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 5', '  Score : 2.5', '  Score : 1.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score: 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.0', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.5', '  Score : 3.0', '  Score : 1.5', '  Score : 4.05. ', '  Score : 3.0', '  Score: 2.0', '  Score : 3.5', '  Score : 3.0', '  score : 4.0', '  Score : 1.5', '  Score : 3.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score: 4.0', '  Score : 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0.', '  Score : 4.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 1.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0.', '  Score : 3.0', '  Score :  3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 1.0 ', '  Score: 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0. The answer gives a complete insight into what a function signature is.', '  Score : 3.0', \"  Score : 4.0 \\\\<br>From the left subtree if the target node is right most node then copy that node in the position node. Then detach that node's subtree else leave that node there.\", '  Score : 2.5', '  Score : 5', '  Score : 5', '  Score : 4.0. Answered the question directly without any ambiguity.', '  Score : 5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0.', '  Score: 2.5', '  Score : 3.0.', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 1.5', '  Score : 2.5', '  Score : 1.5', '  Score : 4.5', '  Score : 2.5', '  Score : 3.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0,', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 1.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.5', '  Score : 4.5', '  Score : 2.5', '  Score : 3.5', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5.', '  Score : 3.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score: 3.5', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.00', '  Score : 3.0', '  Score : 2.0', '  Score : 3.0', '  Score : 5', '  Score : 4.0', '  Score : 3.0', '  Score : [4.0]', '  Score : 3.0', '  Score : 3.5', '  Score : 4.5', '  Score : 3.5', '  Score : 5.0', '  Score : 2.5', '  Score : 4.5', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5', '  Score : 3.5', '  Score : 5.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0.', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0', '  Score : 4.0', '  Score: 4.0', '  Score : 5.0', '  Score: 4.5', '  Score : 2.5 |- The answer is specific. It states that no constructor can be provided to create a default constructor by default.', '  Score : 4.5', '  Score : 4.0 Reflexibe, while its a good basic concept of traversing all direction at once, there are faster methods that can be used like two pointer.', '  Score : 4.0', '  Score: 5.0', '  Score : 2.5', '  Score : 2.5.', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score: 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 2.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 1.0', '  Score : 2.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5 |- Indicates the answer is vague or incorrect.', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 5', '  Score : 1.8', '  Score: 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 4.0', '  Score : 2.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5.', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.0', '  Score : 3.0', '  Score : 4.5', '  Score : 4.0', '  Score: 3.0', '  Score : 4.0', '  Score : 3.0.', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score: 2.5', '  Score : 2.5.', '  Score : 3.0', '  Score : 4.5', '  Score : 3.5', '  Score : 4.5', '  Score : 4.0', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 3.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5', '  Score : 3.0', '  Score : 5.0', '  Score : 5.0', '  Score: 2.5', '  Score : 2.5', '  Score : 2.0', '  Score : 2.5', '  Score : 4.5', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 1.5', '  Score : 2.5', '  Score : 1.5', '  Score : 1.0 MeV', '  Score : 5.0', '  Score : 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 1.5', '  Score : 5.0', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.0', '  Score : 2.0', '  Score: 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 1.0', '  Score : 3.0', '  Score : 5', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.0', '  Score : 4.0', '  Score : 2.5', '  Score : 5.0', '  Score : 4.0', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0,', '  Score : 4.0', '  Score : 2.5', '  Score : 3.5.', '  Score : 4,0', '  Score : 1.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 1.0 ', '  Score : 2.5', '  Score : 2.5.', '  Score : 4.0', '  Score : 1.5', '  Score : 4.0', '  Score : 2.0.', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.5.', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 2.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 3.5', '  Score : 1.0', '  Score : 3.0', '  Score : 3.5', '  Score : 3.0', '  Score : 2.5', '  Score: 2.5', '  Score : 4.0', '  Score : 2.5', '  Score: 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score: 5.0ğı', '  Score : 4.0', '  Score : 4.0', '  Score: 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0 msec', '  Score : 4.0', '  score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 2.0', '  Score : 5', '  Score: 2.5', '  Score : 2.5', '  Score: 1.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.5', '  Score : 2.5', '  Score : 4', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score: 2.0', '  Score : 4.0', '  Score: 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5.', '  Score : 1.0', '  Score : 2.0.', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 1.0', '  Score : 4.0', '  Score : 2.5.', '  Score : 3.5', '  Score : 5.0', '  Score : 5', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score: 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 3.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 5.0', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 2.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0.', '  Score : 4.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5.', '  Score : 2.5', '  Score : 2.5', '  Score : 1.5.', '  Score : 2.5', '  Score : 2.5.', '  Score : 5.0', '  Score : 1.5', '  Score : 2.0', '  Score : 3.0', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score: 4.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0.', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.5', '  Score : 1.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.0', '  Score : 3.0.', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.0', '  Score : 3.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.0', '  Score : 4.0 ', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0 \\\\<score>', '  Score : 3.5', '  Score : 5', '  Score : 2.5', '  Score: 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 1.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 3.0', '  Score : 4', '  Score: 2.5', '  Score : 4.0', '  Score: 4.0', '  Score: 5', '  Score : 5.0', '  Score : 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 1.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.5', '  Score : 4.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 4.0 |]', '  Score : 4.0', '  Score: 3.0', '  Score : 2.5.', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.5', '  Score : 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.5', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score: 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.5', '  Score : 3.5', '  Score : 2.5', '  Score: 3.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score: 2.0', '  Score : 1.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 1.5', '  Score : 5', '  Score : 0.5', '  Score : 5.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score: 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 4.5', '  Score : 2.0', '  Score : 2.0', '  Score : 2.5', '  Score : 4.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score: 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 5', '  Score : 3.0', '  Score: 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.5', '  Score: 3.0', '  Score : 2.0', '  Score : 2.0', '  Score: 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.0', '  Score : 2.5', '  Score : 3.5', '  Score : 5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.0', '  Score : 2.5', '  Score : 3.5', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score: 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score: 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score: 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5 |-The answer demonstrate the concept of an array. However it did not capture it when doing a leetcode problem where we ask to pass the array size to a function.|', '  Score : 5.0', '  Score : 2.5', '  Score : 1.5 ', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.5', '  Score: 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 4.5', '  Score : 2.5', '  Score : 4.5', '  Score : 2.0', '  Score : 3.0', '  Score : 1.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0 Avg', '  Score : 2.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 1.5', '  Score : 4.0', '  Score : 4.0', '  Score : 2.5.', '  Score : 3.0', '  Score : 1.5', '  Score : 4.0', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 5.0', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 5.0', '  Score : 3.0', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 1.5', '  Score : 2.0', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score: 2.5', '  Score : 3.5', '  Score : 2.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0.', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 3.5', '  Score: 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 5.0', '  Score : 2.5', '  Score: 3.0', '  Score : 5.0']\n",
            "['  Score : 4.0', '  Score : 3.5', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.0 NaN.', '  Score : 5', '  Score : 5.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score: 3.0', '  Score : 3.5', '  Score : 5.0', '  Score : 1.5', '  Score : 4.5.', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 1.50', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 4', '  Score : 2.5', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 4.5', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3,', '  Score   : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.5', '  Score : 2.0 .', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5 \\\\<score>]', '  Score : 3.0', '  Score : 3.0.', '  Score : 3.0', '  Score : 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 5', '  Score : 3.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score: 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5.', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5. - RRB -', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score: 3.0', '  Score : 3.0', '  Score : 2.5', '  Score: 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5,', '  Score : 2.5 ', '  Score : 1.0', '  Score : 3.0 Avg', '  Score : 3.0', '  Score : 2.0', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score: 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0.', '  Score : 2.5', '  Score : 3.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.5', '  Score : 2.5', '  Score: 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.0', '  Score : 2.5.', '  Score : 4.0', '  Score : 5.0', '  Score : 4.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 5.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 5', '  Score : 2.5.', '  Score : 1.5.', '  Score : 5.0', '  Score : 3.5', '  Score : 5', '  Score : 3.0', '  Score : 3.0', '  Score : 1.5', '  Score : 1.5', '  Score : 3.0', '  Score : 2.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score : 2.0,', '  Score : 2.5', '  Score : 1.5', '  Score : 3.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 1.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score: 1.0', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score: 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5.', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '   Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0.', '  Score : 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.0', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 3.0', '  Score : 3.5', '  Score : 3.0.', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.5', '  Score : 2.5', '  Score : 2.0', '  Score : 3.0', '  Score : 3.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0', '  Score : 2.0 ', '  Score : 5.0', '  Score : 2.5', '  Score : 5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score: 2.5', '  Score : 2.5', '  Score: 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.0', '  Score : 2.5', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4', '  Score : 4.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score ; 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 1.5', '  Score : 1.5', '  Score : 2.5', '  Score : 3.5', '  Score : 2.5', '  Score : 4.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 1.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 1.5', '  Score : 2.5.', '  Score: 1.5', '  Score : 5.0', '  Score : 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score: 3.0', '  Score : 3.5', '  Score : 3.0', '  Score : 2.0', '  Score : 3.0', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score: 4.0', '  Score : 2.5', '  Score : 4', '  Score : 3.0', '  Score : 5.0', '  Score : 4.0', '  Score: 2.5', '  Score : 3.0. ', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score: 2.5', '  Score : 3.0', '  Score : 5.00', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score: 4.0,', '  Score : 5.0', '  Score : 4.0', '  Score : 2.5', '  Score : 4.5.', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5.', '  Score : 2.5', '  Score : 1.5', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score: 2.5', '  Score : 2.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 5', '  Score : 5.0', '  Score: 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 4.0', '  Score : 2.5.', '  Score: 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 3.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score: 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0 Relax, Insertion sort is still prone to worst case with constant time complexity.', '  Score : 2.5', '  Score : 4.5', '  Score: 2.5.', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score: 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0 stk', '  Score : 1.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 4.0 \\\\<5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0.', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score: 5.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score: 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score: 3.0', '  Score : 4.5', '  Score : 5.0', '  Score : 2.0', '  Score : 4.0', '  Score : 3.0', '  Score : 4.0', '  Score : 4.5', '  Score : 4.5', '  Score : 3.0', '  Score: 3.0', '  Score : 3.0', '  Score : 2.0', '  Score : 3.5', '  Score : 3.0', '  Score : 3.0,', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score: 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score: 5.0', '  Score : 5.00', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3', '  Score: 4.5', '  Score : 4.0', '  Score : 2.5', '  Score : 5.0', '  Score: 4.5 quai', '  Score : 3.0', '  Score : 2.5', '  Score : 5', '  Score : 4.5', '  Score : 4.5', '  Score : 1.0', '  Score : 4.0 Avg. ', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0.', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 5.0', '  Score : 2.5', '  Score: 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score: 3.0', '  Score : 5.0', '  Score : 4', '  Score: 2.5', '  Score : 3.0', '  Score : 3.5', '  Score : 2.0', '  Score : 2.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score : 4.5', '  Score : 5.0', '  Score : 4.0', '  Score: 2.5', '  Score : 5.0', '  Score: 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5.', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 1.5', '  Score : 3.0', '  Score : 1.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5.', '  Score : 3.0', '  Score: 4.5', '  Score : 2.5', '  Score : 2.5.', '  Score : 5.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5 Avg. ', '  Score : 4.0', '  Score : 5.0', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score: 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score: 2.5', '  Score : 2.5', '  Score: 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 3.5', '  Score: 4.0', '  Score : 2.5 XXXV', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5.', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score: 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 4', '  Score : 3.5.', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 5.0', '  Score : 4.5  hyvä ', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score: 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 1.5', '  Score : 2.5 |]', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 1.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0.', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score: 4.0.', '  Score : 4.0', '  Score : 4.5', '  Score : 3.0', '  Score: 5', '  Score : 2.5', '  Score : 4.0', '  Score : 2.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score: 2.5', '  Score : 3.5.', '  Score : 3.0.', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 1.0', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 1.0', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.0', '  Score: 3.0, Comments: Not all students were correct when defining a queue.', '  Score : 2.5', '  Score : 5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score: 4.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.5', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 4.5', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5.', '  Score : 3.0', '  Score : 2.5', '  Score : 1.0', '  Score : 4.0', '  Score : 3.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 4.5,', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score: 3.5', '  Score : 4.5', '  Score : 3.0', '  Score : 4.0', '  Score : 2.5.', '  Score : 2.5', '  Score: 3.0 ', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 5.0', '  Score : 2.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 1.5', '  Score: 1.5', '  Score : 2.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 1.5.', '  Score : 1.5', '  Score : 4.0', '  Score : 3.5', '  Score : 2.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5.', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 4.0', '  Score: 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0.', '  Score : 3.5', '  Score: 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.0', '  Score : 1.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0.', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score: 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 3.5', '  Score : 4.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score: 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.0', '  Score: 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.5', '  Score : 5.0 ', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '   Score : 3.0', '  Score : 2.5', '  Score : 3.5', '  Score : 5.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.5', '  Score : 5.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0,', '  Score : 3.0', '  Score : 5.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 1.5', '  Score : 3.0', '  Score : 5.0', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 5.0', '  Score : 4.0', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.0', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 5.00', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score: 3.0', '  Score : 2.5.', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.0', '  Score : 4.0', '  Score : 3.0', '  Score : 1.5', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 1.0.', '  Score : 3.0', '  Score : 5.0', '  Score: 5.0', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 5.0', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 1.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5', '  Score : 5.0', '  Score: 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 4.5', '  Score : 4.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 4.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 3.0.', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5;', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0', '  Score : 3.5', '  Score : 4.5', '  Score : 2.0 ', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 2.0', '  Score : 4.5', '  Score : 4.0', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 1.5', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 2.5', '  Score: 3.5', '  Score : 2.5', '  Score : 4.0', '  Score : 4.0', '  Score : 5.0', '  Score : 2.5', '  Score : 4.5', '  Score : 2.5', '  Score : 4.5', '  Score : 5.0', '  Score : 2.5', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 1.0', '  Score : 2.5', '  Score : 2.5', '  Score : 2.5', '  Score : 3.0', '  Score : 2.5', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 1.0', '  Score : 3.0', '  Score : 3.0', '  Score: 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 2.5', '  Score : 4.5', '  Score : 3.0', '  Score : 3.0', '  Score : 5.0', '  Score : 2.5', '  Score : 5.0', '  Score : 4.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 3.0.', '  Score : 3.0', '  Score : 3.5', '  Score : 4', '  Score : 3.0', '  Score : 2.5', '  Score : 2.5', '  Score : 4.0', '  Score : 3.0', '  Score : 2.5 Operand associated with a stack are the push and pop mechanisms', '  Score : 2.5', '  Score : 3.0', '  Score : 5', '  Score : 1.5', '  Score : 2.5', '  Score : 3.0', '  Score : 3.0', '  Score : 3.0', '  Score: 2.5', '  Score : 2.5.', '  Score : 2.5', '  Score : 5.0', '  Score : 2.5', '  Score : 3.0', '  Score : 4.0', '  Score : 4.0', '  Score : 4.0.', '  Score : 3.0 ', '  Score : 4.0']\n"
          ]
        }
      ],
      "source": [
        "print(actual_outputs)\n",
        "print(outputs_finetuned)\n",
        "print(outputs_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manually check the values with no guardrails implemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoTIA4pAeFU1",
        "outputId": "822c7f94-ebc7-4041-80c5-1277c24bdb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.0, 5.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.5, 3.0, 3.0, 4.5, 3.5, 2.0, 5.0, 4.5, 5.0, 5.0, 2.5, 4.5, 1.5, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 4.0, 5.0, 5.0, 2.0, 4.5, 3.5, 4.0, 1.0, 3.0, 3.5, 4.5, 4.0, 5.0, 3.0, 2.5, 5.0, 5.0, 4.0, 5.0, 4.5, 2.5, 5.0, 4.0, 3.5, 1.5, 5.0, 3.5, 1.5, 3.0, 5.0, 5.0, 3.0, 2.0, 4.0, 5.0, 5.0, 4.0, 4.5, 4.0, 4.5, 5.0, 5.0, 4.5, 3.0, 4.0, 4.5, 0.0, 4.0, 3.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.5, 2.5, 3.0, 2.5, 3.5, 3.0, 5.0, 5.0, 4.5, 3.5, 5.0, 5.0, 5.0, 4.5, 3.5, 5.0, 4.0, 4.0, 4.5, 1.5, 5.0, 5.0, 2.0, 5.0, 2.0, 4.5, 5.0, 2.0, 5.0, 4.5, 4.0, 3.5, 2.0, 1.5, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 3.5, 4.0, 5.0, 4.5, 4.0, 4.5, 5.0, 1.0, 2.5, 3.0, 4.5, 3.5, 5.0, 4.5, 2.5, 2.0, 5.0, 3.5, 5.0, 4.0, 4.0, 5.0, 1.5, 3.5, 4.0, 5.0, 3.0, 4.5, 5.0, 5.0, 4.5, 3.5, 5.0, 5.0, 4.5, 2.5, 5.0, 5.0, 5.0, 5.0, 3.0, 2.5, 5.0, 1.0, 3.5, 4.5, 5.0, 5.0, 5.0, 5.0, 4.5, 1.5, 5.0, 2.0, 5.0, 3.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 0.0, 4.5, 5.0, 4.0, 2.5, 5.0, 3.5, 5.0, 4.5, 2.0, 5.0, 5.0, 4.5, 3.5, 2.5, 3.5, 4.5, 4.0, 4.5, 1.0, 5.0, 5.0, 3.5, 5.0, 5.0, 5.0, 4.0, 5.0, 4.5, 5.0, 5.0, 3.5, 4.0, 4.5, 4.5, 5.0, 3.5, 5.0, 4.0, 3.0, 5.0, 3.5, 5.0, 3.0, 5.0, 5.0, 5.0, 0.0, 5.0, 0.0, 5.0, 3.5, 4.5, 5.0, 4.5, 4.5, 5.0, 3.0, 4.0, 5.0, 2.5, 3.5, 3.0, 4.0, 4.0, 5.0, 1.0, 5.0, 2.5, 4.0, 3.5, 4.0, 1.5, 5.0, 5.0, 3.5, 5.0, 3.5, 5.0, 5.0, 5.0, 2.5, 4.5, 5.0, 5.0, 4.0, 4.0, 4.5, 5.0, 5.0, 2.0, 5.0, 5.0, 4.5, 2.0, 1.0, 2.0, 4.0, 5.0, 4.0, 5.0, 4.0, 2.5, 4.5, 5.0, 3.0, 4.5, 5.0, 4.0, 4.5, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 3.5, 3.5, 4.5, 5.0, 5.0, 4.5, 4.5, 5.0, 5.0, 5.0, 4.5, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.5, 3.0, 4.0, 3.5, 5.0, 5.0, 3.5, 4.0, 4.5, 2.5, 5.0, 2.0, 5.0, 5.0, 2.5, 5.0, 4.0, 3.5, 5.0, 5.0, 3.5, 5.0, 5.0, 3.5, 4.0, 3.0, 4.5, 3.5, 2.0, 5.0, 5.0, 4.0, 4.0, 5.0, 3.5, 5.0, 5.0, 2.5, 4.0, 3.0, 3.0, 5.0, 4.0, 5.0, 2.0, 5.0, 5.0, 5.0, 5.0, 4.5, 2.0, 5.0, 4.0, 2.0, 3.5, 5.0, 5.0, 5.0, 2.5, 4.0, 5.0, 4.0, 4.5, 3.5, 4.5, 4.5, 4.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 4.5, 5.0, 4.5, 5.0, 5.0, 5.0, 4.5, 3.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.5, 5.0, 5.0, 5.0, 4.0, 2.5, 3.0, 3.5, 3.0, 5.0, 3.5, 5.0, 2.5, 3.0, 5.0, 4.5, 4.0, 3.0, 3.0, 4.5, 4.5, 5.0, 3.0, 3.5, 4.0, 4.0, 4.5, 3.5, 5.0, 2.0, 5.0, 4.0, 3.5, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 3.5, 3.0, 2.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.5, 5.0, 4.0, 1.5, 5.0, 5.0, 4.0, 5.0, 5.0, 4.5, 5.0, 4.0, 5.0, 4.0, 3.5, 2.5, 5.0, 5.0, 2.5, 5.0, 2.5, 5.0, 5.0, 5.0, 5.0, 3.5, 3.5, 4.0, 5.0, 3.0, 5.0, 5.0, 4.5, 5.0, 1.5, 5.0, 3.5, 3.0, 5.0, 5.0, 5.0, 5.0, 1.0, 4.5, 2.5, 3.5, 4.0, 2.0, 5.0, 5.0, 4.0, 5.0, 4.0, 2.0, 4.5, 1.5, 4.5, 5.0, 5.0, 4.5, 1.5, 5.0, 5.0, 5.0, 4.5, 4.5, 4.5, 4.0, 3.0, 3.0, 4.0, 5.0, 2.5, 5.0, 5.0, 5.0, 5.0, 4.0, 3.5, 4.5, 4.0, 4.5, 3.5, 3.0, 5.0, 5.0, 4.0, 2.0, 3.0, 3.5, 4.0, 4.5, 2.5, 5.0, 3.5, 4.0, 4.5, 4.0, 5.0, 3.5, 5.0, 2.5, 4.0, 3.0, 2.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 2.0, 5.0, 4.5, 4.0, 2.5, 3.0, 0.0, 3.5, 4.5, 3.0, 5.0, 5.0, 3.5, 3.5, 2.5, 5.0, 3.0, 4.5, 5.0, 5.0, 5.0, 3.5, 2.5, 5.0, 5.0, 4.0, 5.0, 2.5, 4.5, 4.5, 3.5, 4.5, 4.5, 4.5, 5.0, 2.5, 3.5, 3.5, 4.0, 5.0, 2.5, 5.0, 5.0, 2.5, 5.0, 4.5, 5.0, 5.0, 2.5, 5.0, 4.5, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 2.5, 4.5, 3.5, 5.0, 5.0, 4.5, 5.0, 5.0, 5.0, 4.5, 4.0, 4.5, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0, 4.5, 1.0, 3.0, 5.0, 5.0, 0.0, 4.5, 5.0, 5.0, 5.0, 2.5, 2.5, 3.0, 5.0, 5.0, 4.5, 2.5, 5.0, 2.0, 0.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 4.5, 3.0, 5.0, 3.5, 5.0, 3.0, 5.0, 5.0, 1.5, 5.0, 3.5, 5.0, 5.0, 5.0, 5.0, 2.0, 4.5, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 2.5, 3.0, 3.5, 4.0, 5.0, 5.0, 5.0, 3.0, 4.0, 4.5, 3.0, 4.5, 5.0, 5.0, 2.5, 4.5, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 5.0, 4.5, 4.5, 4.5, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 4.0, 3.0, 4.5, 5.0, 4.0, 5.0, 3.5, 2.5, 4.5, 5.0, 5.0, 4.5, 3.5, 3.5, 5.0, 2.0, 3.5, 5.0, 4.5, 3.5, 2.5, 5.0, 5.0, 2.0, 5.0, 4.5, 2.5, 4.5, 4.0, 5.0, 5.0, 3.0, 5.0, 4.5, 2.5, 3.0, 2.0, 4.0, 2.5, 5.0, 4.0, 3.5, 4.0, 2.5, 4.0, 3.5, 5.0, 4.5, 4.0, 4.0, 4.0, 5.0, 5.0, 3.5, 5.0, 3.5, 4.0, 5.0, 3.0, 5.0, 3.5, 5.0, 1.0, 5.0, 4.5, 5.0, 4.0, 5.0, 3.5, 2.5, 4.0, 1.5, 5.0, 4.5, 5.0, 4.5, 3.0, 5.0, 4.5, 2.5, 2.5, 5.0, 5.0, 5.0, 4.5, 5.0, 2.5, 5.0, 5.0, 5.0, 3.5, 5.0, 5.0, 3.5, 2.0, 5.0, 2.0, 1.5, 4.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 2.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 5.0, 5.0, 4.0, 2.0, 5.0, 2.0, 5.0, 3.5, 5.0, 4.5, 5.0, 5.0, 5.0, 3.5, 5.0, 5.0, 4.0, 2.5, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.5, 4.5, 5.0, 4.5, 5.0, 5.0, 5.0, 4.5, 5.0, 4.5, 5.0, 4.5, 4.5, 2.5, 5.0, 4.0, 5.0, 3.5, 4.0, 2.5, 4.0, 4.0, 4.0, 5.0, 3.0, 4.0, 4.0, 1.0, 3.5, 3.5, 1.0, 5.0, 3.0, 5.0, 4.5, 3.5, 0.0, 4.5, 5.0, 4.5, 3.0, 5.0, 4.5, 3.5, 3.5, 5.0, 4.0, 2.0, 3.5, 4.5, 5.0, 3.5, 5.0, 4.0, 0.0, 3.5, 5.0, 5.0, 5.0, 5.0, 4.0, 2.5, 4.5, 5.0, 5.0, 5.0, 4.5, 1.5, 3.5, 4.0, 5.0, 4.0, 1.5, 4.0, 4.5, 3.5, 2.0, 4.5, 4.5, 3.5, 5.0, 5.0, 4.0, 5.0, 5.0, 2.5, 5.0, 5.0, 2.5, 3.5, 5.0, 4.5, 2.5, 0.5, 5.0, 3.5, 5.0, 4.5, 5.0, 1.0, 5.0, 4.5, 5.0, 2.0, 5.0, 5.0, 4.5, 3.5, 4.5, 3.5, 4.5, 5.0, 5.0, 5.0, 3.0, 0.0, 3.0, 3.0, 5.0, 5.0, 5.0, 0.0, 5.0, 4.0, 5.0, 4.5, 3.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 5.0, 5.0, 1.5, 4.5, 2.0, 3.0, 1.0, 5.0, 4.5, 5.0, 4.5, 5.0, 5.0, 5.0, 5.0, 4.5, 5.0, 4.0, 2.5, 4.0, 3.5, 3.0, 2.0, 5.0, 5.0, 5.0, 5.0, 2.5, 5.0, 4.0, 5.0, 4.5, 3.5, 2.5, 5.0, 3.5, 5.0, 1.5, 5.0, 4.5, 5.0, 4.5, 3.5, 5.0, 2.5, 3.0, 4.5, 4.5, 0.0, 4.0, 3.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.5, 3.5, 3.0, 5.0, 3.5, 2.0, 5.0, 5.0, 4.0, 3.0, 2.5, 4.5, 2.0, 5.0, 3.0, 4.5, 4.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 1.5, 4.0, 5.0, 5.0, 4.5, 5.0, 4.0, 4.5, 4.0, 2.5, 5.0, 5.0, 5.0, 5.0, 4.5, 2.0, 4.5, 3.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.5, 4.0, 0.0, 5.0, 4.5, 5.0, 5.0, 4.5, 3.0, 5.0, 5.0, 4.5, 5.0, 1.0, 5.0, 2.5, 5.0, 2.5, 2.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 5.0, 3.0, 5.0, 5.0, 5.0, 2.5, 2.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.5, 3.0, 3.5, 5.0, 4.0, 0.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.5, 4.5, 5.0, 5.0, 4.0, 3.5, 4.5, 4.0, 5.0, 4.5, 3.0, 4.5, 2.5, 3.5, 3.5, 3.5, 5.0, 1.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 4.0, 5.0, 4.0, 4.5, 3.0, 5.0, 5.0, 3.5, 5.0, 5.0, 1.0, 5.0, 5.0, 4.0, 5.0, 3.0, 4.0, 5.0, 1.5, 4.0, 5.0, 2.5, 4.0, 5.0, 5.0, 5.0, 4.0, 4.5, 4.0, 3.5, 2.0, 3.0, 5.0, 2.5, 5.0]\n",
            "[2.5, 4.0, 2.5, 2.0, 3.0, 2.5, 2.0, 4.0, 3.5, 5.0, 3.0, 5.0, 3.0, 5.0, 3.0, 2.0, 3.0, '  Score : 4,0', 4.0, 3.0, 1.5, 3.0, 3.0, 2.5, 2.5, 3.0, 3.0, 4.0, 3.0, 2.5, 3.0, 4.0, 5.0, 2.5, 4.5, 2.5, 3.5, 3.0, 4.5, 3.0, 2.5, 4.0, 4.5, 2.5, 3.0, 3.0, 4.5, 3.0, 4.0, 4.0, 2.5, 3.5, 3.0, 3.0, 3.5, 2.0, 5.0, 3.0, 4.0, '  Score : 2.5.', 2.5, 3.0, 3.0, 2.5, 5.0, 2.5, '  Score : 2.5.', 3.0, 4.0, '  Score : 2.5.', 4.0, 2.5, 3.0, 3.0, 2.5, 2.5, 3.5, 5.0, 5.0, 2.5, 4.0, 2.0, '  Score : 2.0.', 3.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 1.5, 3.0, 3.0, 4.0, 4.5, 2.0, 4.0, 3.0, 3.0, 3.0, 2.5, 3.0, 2.5, 2.5, 4.0, 3.0, 4.0, 4.5, 5.0, 3.0, 3.0, 2.5, 3.0, 3.0, '  Score : 2.5.', 2.5, 5.0, 3.0, 3.0, 5.0, 2.5, 3.0, 3.0, 1.5, 3.5, 2.5, 4.0, 4.5, '  Score : 2.5.', 2.5, '  Score : 3.0.', 2.5, 1.5, 4.5, 4.0, '  Score : 1.5,', 3.5, 5.0, 3.5, 2.5, 2.5, 4.0, 3.0, 5.0, '  Score : 3.0,', 4.0, 5.0, 5.0, 2.5, 3.0, 1.5, 2.5, 4.0, 3.0, '  Score : 4.0.', 2.5, 2.5, 3.0, 3.0, 2.5, 2.5, 2.5, 3.0, 5.0, 5.0, 2.5, 2.5, 5.0, 2.5, 2.0, '  Score : 2.0.', 4.5, 2.0, 3.0, 2.5, 3.0, 3.0, 3.0, 5.0, 2.5, 2.5, 5.0, '  Score : 3.5.', 3.0, 1.5, '  Score : 2.5.', 2.5, 4.0, 5.0, 5.0, 3.0, '  Score : 3.0.', 2.5, 2.5, 2.5, 2.5, 5.0, 3.0, 5.0, 3.0, '  Score : 1.5.', 3.0, 4.0, 5.0, 5.0, '  Score : 2.5.', 3.0, 5.0, 3.0, 2.5, 4.0, 2.5, 2.5, 5.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.5, 5.0, 2.5, 2.5, 3.0, 3.0, 3.0, 2.5, 4.5, 4.0, 3.0, 4.5, 4.0, '  Score : 2.5.', 4.0, 2.5, 5.0, 3.0, 2.0, 4.5, 3.0, 5.0, 3.0, 4.0, 4.0, 2.5, 2.5, 2.5, 3.5, 2.5, 3.0, 5.0, 2.5, 3.0, 3.0, 2.5, 3.0, 2.5, 3.0, 4.0, 3.0, 2.5, 3.0, 4.0, 2.5, 2.5, 5.0, 2.5, 5.0, 3.0, 5.0, 2.5, 1.5, 2.5, 2.5, 2.5, 4.0, 2.5, 3.0, 3.0, 3.0, 4.0, 3.0, 2.5, 4.5, 2.5, 2.5, 2.0, 1.5, 2.5, 3.0, 2.5, 3.0, 3.0, 3.0, 3.5, 3.0, 1.5, '  Score : 4.05. ', 3.0, 2.0, 3.5, 3.0, 4.0, 1.5, 3.5, 2.5, 3.0, 2.0, 2.5, 2.5, 2.5, 5.0, 3.0, 3.0, 4.0, 3.0, 4.5, 2.5, 2.5, 3.0, 2.5, 2.5, 5.0, '  Score : 3.0.', 4.5, 4.0, 3.0, 2.5, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.5, 3.0, 4.0, 2.0, 3.0, 3.0, '  Score : 3.0.', 3.0, '  Score :  3.0', 3.0, 3.0, 3.0, 2.5, 3.0, 3.0, 5.0, 1.0, 4.0, 3.0, 2.5, 3.0, 4.5, 3.0, 2.5, 2.5, 2.5, 4.0, 3.0, 2.5, '  Score : 5.0. The answer gives a complete insight into what a function signature is.', 3.0, 4.0, 2.5, 5.0, 5.0, '  Score : 4.0. Answered the question directly without any ambiguity.', 5.0, 5.0, 3.0, '  Score : 3.0.', 2.5, '  Score : 3.0.', 3.0, 3.0, 3.0, 2.5, 3.5, '  Score : 3.0.', 2.5, 2.5, 5.0, 3.0, 2.5, 1.5, 2.5, 1.5, 4.5, 2.5, 3.5, 2.5, 3.0, '  Score : 4.0,', 2.5, 3.0, 2.5, 1.0, 2.5, 3.0, 3.0, 2.5, 2.5, 2.5, 3.5, 4.5, 2.5, 3.5, 2.5, 4.5, 2.5, 2.5, 2.5, '  Score : 2.5.', 3.5, 2.5, 2.5, 3.0, 3.0, 2.5, 4.0, 2.5, 3.0, 5.0, 2.5, 2.5, 3.0, 3.0, 3.5, 5.0, 2.5, 4.0, 4.5, 3.0, 4.0, 3.0, 2.5, 4.0, 3.0, 2.0, 3.0, 5.0, 4.0, 3.0, '  Score : [4.0]', 3.0, 3.5, 4.5, 3.5, 5.0, 2.5, 4.5, 4.5, 2.5, 3.0, 2.5, 2.5, 5.0, 3.0, 3.0, 2.5, 2.5, 3.0, 3.0, 5.0, 3.5, 5.0, 3.0, 4.0, 2.5, 1.5, '  Score : 3.0.', 3.0, 4.0, 2.5, 1.5, 3.0, 4.0, 4.0, 5.0, 4.5, 2.5, 4.5, 4.0, 4.0, 5.0, 2.5, '  Score : 2.5.', 5.0, 2.5, 3.0, 2.5, 1.5, 3.0, 2.5, 5.0, 4.5, 3.0, 2.5, 3.0, 2.5, 5.0, 3.0, 2.0, 2.5, 4.0, 4.0, 2.5, 3.0, 1.0, 2.0, 3.0, 3.0, 2.5, 3.0, 3.0, 3.0, 4.0, 5.0, 2.5, 3.0, 5.0, 2.5, 4.0, 3.0, 5.0, 1.8, 2.5, 2.5, 3.0, 4.5, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.5, 2.5, 2.5, 4.0, 5.0, 2.5, 3.0, 3.0, 2.5, 5.0, 2.5, 2.5, 2.5, 3.0, 3.0, '  Score : 2.5.', 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.5, 2.0, 3.0, 4.5, 4.0, 3.0, 4.0, '  Score : 3.0.', 3.0, 3.0, 2.5, 4.0, 3.0, 4.0, 5.0, 2.5, '  Score : 2.5.', 3.0, 4.5, 3.5, 4.5, 4.0, 3.0, 5.0, 3.0, 2.5, 4.0, 2.0, 2.5, 2.5, 3.0, 4.5, 3.0, 2.5, 4.5, 2.5, 3.5, 3.0, 2.5, 2.5, 5.0, 3.0, 5.0, 5.0, 2.5, 2.5, 2.0, 2.5, 4.5, 1.5, 3.0, 2.5, 3.0, 4.5, 1.5, 2.5, 1.5, 1.0, 5.0, 2.0, 2.5, 2.5, 2.5, 4.5, 3.0, 1.5, 5.0, 3.0, 4.5, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.5, 3.0, 3.0, 1.0, 1.0, 3.0, 5.0, 2.5, 4.0, 2.5, 3.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.5, 5.0, 4.0, 1.5, 3.0, 2.5, '  Score : 4.0,', 4.0, 2.5, '  Score : 3.5.', '  Score : 4,0', 1.0, 3.0, 3.0, 1.0, 3.0, 2.5, 2.5, 2.5, 2.5, 2.5, 4.0, 3.0, 1.0, 2.5, '  Score : 2.5.', 4.0, 1.5, 4.0, '  Score : 2.0.', 5.0, 3.0, 2.5, 5.0, 2.5, 3.0, 2.5, 2.5, '  Score : 3.5.', 3.0, 2.5, 2.5, 4.0, 2.5, 2.5, 2.5, 4.5, 2.0, 2.5, 3.0, 2.0, 3.5, 1.0, 3.0, 3.5, 3.0, 2.5, 2.5, 4.0, 2.5, 5.0, 2.5, 2.5, 3.0, 2.5, '  Score: 5.0ğı', 4.0, 4.0, 2.5, 4.0, 3.0, 2.5, 3.0, 4.0, 2.5, 3.0, 2.5, 3.0, 3.0, 5.0, 4.0, 3.0, 3.0, 3.0, 2.5, 2.5, 2.5, 3.0, 4.5, 2.5, 2.0, 5.0, 2.5, 2.5, 1.5, 2.5, 2.5, 3.0, 3.0, 5.0, 2.5, 4.5, 2.5, 2.5, 2.5, 2.5, 2.5, 5.0, 3.0, 4.5, 2.5, 3.0, 3.5, 2.5, 4.0, 2.5, 3.0, 3.0, 2.5, 2.0, 4.0, 4.5, 3.0, 2.5, '  Score : 2.5.', 1.0, '  Score : 2.0.', 5.0, 3.0, 3.0, 2.5, 1.0, 4.0, '  Score : 2.5.', 3.5, 5.0, 5.0, 2.5, 4.0, 2.5, 2.5, 5.0, 2.5, 4.0, 3.0, 3.0, 4.5, 3.0, 2.5, 3.0, 3.0, 3.0, 4.5, 2.5, 3.5, 3.0, 2.5, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 2.5, 4.0, 5.0, 1.5, 2.5, 3.0, 4.0, 2.5, 4.0, 3.0, 3.0, 1.0, 2.5, '  Score : 3.0.', 2.5, 3.0, 3.0, 2.5, '  Score : 3.0.', 4.0, 3.0, 5.0, '  Score : 2.5.', 2.5, 2.5, '  Score : 1.5.', 2.5, '  Score : 2.5.', 5.0, 1.5, 2.0, 3.0, 2.5, 1.5, 3.0, 4.0, 2.5, 4.0, 3.0, 2.5, 4.5, 3.0, 4.0, 3.0, '  Score : 4.0.', 3.0, 3.0, 3.0, 3.0, 1.5, 1.5, 3.0, 4.0, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, '  Score : 3.0.', 2.5, 3.0, 4.0, 2.0, 3.5, 4.0, 2.5, 2.0, 4.0, 3.0, 2.5, 3.0, 3.5, 5.0, 2.5, 2.5, 5.0, 2.5, 4.0, 3.5, 3.0, 5.0, 3.0, 4.0, 2.5, 1.5, 4.0, 3.0, 2.5, 4.5, '  Score : 3.0.', 2.5, 3.0, 4.0, 2.5, 4.0, 4.0, 5.0, 5.0, 4.5, 2.5, 2.5, 4.0, 1.5, 3.0, 3.0, 3.0, 3.5, 4.5, 4.0, 3.0, 2.5, 5.0, 5.0, 3.0, 2.5, 4.5, 4.0, 4.0, 3.0, '  Score : 2.5.', 4.0, 3.0, 3.0, 3.0, 4.0, 2.5, 2.5, 3.5, 2.0, 2.5, 2.5, 2.5, 3.5, 4.5, 3.0, 3.0, 2.5, 2.5, 3.0, 2.5, 2.5, 3.5, 3.5, 2.5, 3.5, 3.0, 2.5, 5.0, 3.0, 2.5, '  Score : 3.0.', 2.5, 3.0, 2.5, 5.0, 2.5, 2.5, 2.0, 1.0, 5.0, 2.5, 4.0, 1.5, 5.0, 0.5, 5.0, 5.0, 2.5, 4.0, 2.5, 3.0, 4.0, 3.0, 2.5, 2.5, 3.0, 2.5, 5.0, 2.5, 5.0, 2.5, 3.0, 4.5, 4.5, 2.0, 2.0, 2.5, 4.5, 4.0, 3.0, 2.5, 2.5, 2.5, 3.0, 4.0, 5.0, 2.5, 3.0, 4.5, 5.0, 3.0, 2.0, 2.5, 2.5, 2.5, 2.5, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.5, 3.0, 2.0, 2.0, 3.0, 5.0, 2.5, 2.0, 2.5, 3.5, 5.0, 2.5, 3.0, 4.0, 3.0, 2.0, 2.5, 3.5, 1.5, 2.5, 3.0, 2.5, 3.0, 2.5, 2.5, 4.0, 2.5, 2.5, 3.0, 3.0, 3.0, 5.0, 2.5, 2.5, 2.5, 2.5, 4.0, 5.0, 2.5, 2.5, 5.0, 2.5, 1.5, 2.5, 4.0, 3.0, 3.5, 2.5, 2.5, 5.0, 4.5, 2.5, 4.5, 2.0, 3.0, 1.5, 3.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.5, 5.0, 4.0, 2.5, 3.0, 2.5, 4.5, 5.0, 2.5, 3.0, 5.0, 2.5, 3.0, 2.5, 1.5, 4.0, 4.0, '  Score : 2.5.', 3.0, 1.5, 4.0, 4.0, 2.5, 2.5, 5.0, 3.0, 3.0, 1.0, 5.0, 4.0, 4.0, 3.0, 5.0, 2.5, 4.0, 3.0, 2.5, 2.5, 3.0, 2.5, 3.0, 4.5, 5.0, 3.0, 1.5, 3.0, 2.5, 2.5, 4.5, 5.0, 2.5, 3.0, 1.5, 2.0, 4.0, 2.5, 2.5, 3.0, 1.5, 2.5, 3.0, 4.0, 3.0, 2.5, 3.0, 2.5, 3.0, 3.5, 3.0, 2.5, 4.5, 2.0, 5.0, 3.0, 3.0, 3.0, 2.5, 3.0, 5.0, 4.0, 3.0, 3.0, 2.5, 3.0, 4.0, 2.5, 3.5, 2.0, 3.0, 3.0, '  Score : 3.0.', 4.0, 3.0, 3.0, 2.5, 3.0, 2.5, 4.5, 3.5, 4.0, 2.5, 2.5, 2.5, 2.5, 3.0, 2.5, 2.5, 3.0, 2.0, 2.5, 2.5, 3.0, 4.5, 5.0, 2.5, 3.0, 5.0]\n",
            "[4.0, 3.5, 2.5, 4.5, 3.0, 3.0, 2.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.5, 3.0, 3.5, 5.0, 1.5, '  Score : 4.5.', 2.5, 3.0, 3.0, 1.5, 2.5, 2.5, 3.0, 4.0, 3.0, 2.5, 3.0, 4.0, 4.0, 2.5, 1.5, 2.5, 3.0, 3.0, 4.5, 4.5, 2.5, 3.0, '  Score : 3,', 2.5, 3.0, 4.0, 3.0, 2.5, 1.5, 3.0, 2.5, 4.0, 4.5, 2.0, 3.0, 3.0, 4.0, 2.5, 3.0, 2.5, 3.0, 3.0, 4.5, 3.0, 3.0, 5.0, 2.5, 3.0, '  Score : 3.0.', 3.0, 3.0, 4.5, 2.5, 3.0, 5.0, 3.5, 3.0, 3.0, 2.5, 4.5, 5.0, 3.0, 3.0, 3.0, 2.5, 4.5, 3.0, 2.5, '  Score : 2.5.', 2.5, 2.5, 3.0, 4.0, 4.0, 3.0, 3.0, 1.5, 2.5, 3.0, 4.0, 2.5, 3.0, 3.0, 2.5, 2.5, 2.5, 4.0, 2.5, 2.5, 4.5, 5.0, 3.0, 2.5, 4.0, 2.5, 3.0, '  Score : 4.5. - RRB -', 5.0, 2.5, 3.0, 3.0, 3.0, 2.5, 5.0, 2.5, 3.0, 2.5, 3.0, 5.0, 3.0, 2.5, 3.0, 2.5, 2.5, 3.0, 2.5, 3.0, '  Score : 2.5,', 2.5, 1.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 2.5, 2.5, 4.0, 2.5, 2.5, 2.5, 4.5, 4.0, 3.0, '  Score : 3.0.', 2.5, 3.5, 2.5, 2.5, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.5, 2.5, 2.5, 3.0, 4.0, 3.0, 5.0, 3.0, 3.0, 1.5, 2.5, 4.0, 4.0, 3.0, 2.0, '  Score : 2.5.', 4.0, 5.0, 4.5, 5.0, 2.5, 3.0, 3.0, 2.5, 3.0, 5.0, 3.0, 5.0, 4.5, 3.0, 2.5, 3.0, 2.5, 3.5, 4.0, 2.5, 3.0, 3.0, 1.0, 5.0, '  Score : 2.5.', '  Score : 1.5.', 5.0, 3.5, 5.0, 3.0, 3.0, 1.5, 1.5, 3.0, 2.0, 5.0, 2.5, 2.5, 4.0, 4.0, 3.0, 2.5, 2.5, 4.0, 3.0, 4.0, 5.0, '  Score : 2.0,', 2.5, 1.5, 3.5, 2.5, 2.5, 2.5, 3.0, 2.5, 4.0, 5.0, 2.5, 4.0, 2.5, 3.5, 2.5, 2.5, 4.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.5, 3.0, 2.5, 4.5, 5.0, 2.5, 2.5, 2.5, 3.0, 2.5, 4.0, '  Score : 2.5.', 3.0, 2.5, 2.5, 2.5, 2.5, 5.0, 5.0, 2.5, 3.0, 2.5, 2.5, 2.5, 3.0, 2.5, '  Score : 3.0.', 4.5, 2.5, 2.5, 2.5, 2.5, 3.0, 3.0, 5.0, 2.0, 4.5, 3.0, 3.0, 3.5, 2.5, 3.0, 2.0, 3.0, 3.5, '  Score : 3.0.', 4.0, 2.5, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 4.0, 2.5, 4.0, 4.5, 2.5, 2.0, 3.0, 3.5, 5.0, 3.0, 3.0, 3.5, 5.0, 2.5, 3.0, 2.5, 4.5, 3.0, 2.5, 1.5, 3.0, 2.0, 5.0, 2.5, 5.0, 2.5, 3.0, 2.5, 3.0, 2.5, 4.0, 4.0, 3.0, 4.0, 2.5, 2.5, 2.5, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.5, 3.0, 3.0, 2.5, 2.0, 2.5, 4.0, 5.0, 2.5, 4.0, 4.0, 3.0, 5.0, 2.5, 3.0, 3.0, 3.0, 1.5, 4.0, 2.5, 2.5, '  Score ; 2.5', 3.0, 2.5, 5.0, 2.5, 3.0, 1.5, 1.5, 2.5, 3.5, 2.5, 4.5, 4.0, 3.0, 3.0, 3.0, 4.0, 1.5, 2.5, 2.5, 2.5, 4.5, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.5, 2.5, 1.5, '  Score : 2.5.', 1.5, 5.0, 3.0, 4.5, 2.5, 3.0, 3.0, 3.5, 3.0, 2.0, 3.0, 1.5, 2.5, 3.0, 2.5, 3.0, 2.5, 3.0, 2.5, 4.0, 4.0, 2.5, 4.0, 3.0, 5.0, 4.0, 2.5, '  Score : 3.0. ', 2.5, 4.0, 2.5, 2.5, 3.0, 5.0, 2.5, 3.0, 2.5, 3.0, 5.0, 2.5, 3.0, 2.5, 4.5, 3.0, 3.0, 3.0, 3.0, 3.0, '  Score: 4.0,', 5.0, 4.0, 2.5, '  Score : 4.5.', 3.0, 5.0, 3.0, 2.5, 3.5, 3.0, 3.0, 2.5, 3.0, 4.0, 4.5, 2.5, 2.5, '  Score : 2.5.', 2.5, 1.5, 2.5, 1.5, 3.0, 2.5, 2.5, 2.5, 2.5, 2.5, 3.0, 2.5, 3.0, 5.0, 4.0, 4.0, 3.0, 2.5, 4.0, 2.5, 2.0, 3.0, 2.5, 3.0, 2.5, 3.0, 5.0, 5.0, 2.5, 2.5, 3.0, 4.0, 4.0, '  Score : 2.5.', 2.5, 3.0, 5.0, 3.5, 2.5, 3.0, 4.0, 3.0, 5.0, 3.0, 5.0, 2.5, 3.0, 3.0, 4.0, 2.5, 3.0, 2.5, 3.0, 3.0, 2.5, 4.5, '  Score: 2.5.', 3.0, 5.0, 3.0, 2.5, 2.5, 4.0, 4.0, 2.5, 2.5, 5.0, 2.5, 3.0, 3.0, 2.5, 4.0, 4.0, 3.0, 2.5, 5.0, 2.5, 2.5, 3.0, 2.0, 1.0, 3.0, 2.5, 4.0, 5.0, 3.0, 3.0, 2.5, 5.0, 4.0, 3.0, 3.0, '  Score : 3.0.', 2.5, 3.0, 3.0, 3.0, 5.0, 4.0, 2.5, 3.0, 3.0, 3.0, 3.0, 5.0, 2.5, 4.0, 2.5, 4.0, 4.0, 3.0, 3.0, 2.5, 5.0, 3.0, 3.0, 3.0, 2.5, 3.0, 4.5, 5.0, 2.0, 4.0, 3.0, 4.0, 4.5, 4.5, 3.0, 3.0, 3.0, 2.0, 3.5, 3.0, '  Score : 3.0,', 2.5, 2.5, 2.5, 5.0, 2.5, 2.5, 2.5, 3.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.5, 3.0, 2.0, 5.0, 2.5, 2.0, 4.0, 2.5, 3.0, 4.5, 4.0, 2.5, 5.0, 4.5, 3.0, 2.5, 5.0, 4.5, 4.5, 1.0, 4.0, 3.0, 2.5, 3.0, 3.0, 3.0, 3.0, 5.0, 2.5, 3.0, 2.5, 2.5, '  Score : 3.0.', 3.0, 4.0, 3.0, 2.5, 2.5, 5.0, 5.0, 2.5, 2.5, 3.0, 2.5, 5.0, 2.5, 3.0, 5.0, 4.0, 2.5, 3.0, 3.5, 2.0, 2.0, 2.5, 3.0, 2.5, 4.5, 2.5, 3.0, 4.0, 5.0, 4.5, 5.0, 4.0, 2.5, 5.0, 3.0, 2.5, 2.5, 2.5, '  Score : 2.5.', 3.0, 2.5, 4.0, 2.5, 1.5, 3.0, 1.0, 2.5, 4.0, 3.0, 3.0, 4.0, '  Score : 2.5.', 3.0, 4.5, 2.5, '  Score : 2.5.', 5.0, 5.0, 3.0, 3.0, 4.0, 2.5, 4.0, 5.0, 3.0, 4.0, 2.5, 4.0, 4.0, 4.5, 2.5, 3.0, 4.5, 2.5, 2.5, 4.5, 2.5, 2.5, 2.5, 3.0, 5.0, 3.0, 2.5, 4.5, 3.5, 4.0, 2.5, 3.0, 3.0, '  Score : 2.5.', 3.0, 3.0, 3.0, 4.0, 4.0, 5.0, 2.5, 4.5, 2.5, 4.0, '  Score : 3.5.', 2.5, 2.5, 4.0, 5.0, 4.5, 4.0, 3.0, 3.0, 2.5, 2.5, 2.5, 2.5, 5.0, 3.0, 1.5, 2.5, 2.5, 5.0, 2.5, 2.5, 5.0, 3.0, 4.5, 3.0, 1.5, 5.0, 3.0, 3.0, 2.5, 4.0, 4.0, 1.5, 2.5, '  Score : 3.0.', 3.0, 2.5, 2.5, '  Score: 4.0.', 4.0, 4.5, 3.0, 5.0, 2.5, 4.0, 2.0, 5.0, 2.5, 2.5, 2.5, 2.5, '  Score : 3.5.', '  Score : 3.0.', 3.0, 5.0, 3.0, 3.0, 1.0, 2.5, 5.0, 2.5, 1.0, 4.0, 2.5, 2.5, 2.5, 2.0, '  Score: 3.0, Comments: Not all students were correct when defining a queue.', 2.5, 5.0, 3.0, 4.0, 3.0, 2.5, 4.5, 4.0, 3.0, 3.0, 2.5, 2.5, 3.0, 2.5, 3.5, 3.0, 5.0, 2.5, 2.5, 4.0, 4.5, 3.0, 4.5, 3.0, '  Score : 2.5.', 3.0, 2.5, 1.0, 4.0, 3.5, 2.5, 2.5, 2.5, 3.0, 2.5, '  Score : 3.0.', 2.5, '  Score : 4.5,', 2.5, 2.5, 2.5, 3.5, 4.5, 3.0, 4.0, '  Score : 2.5.', 2.5, 3.0, 3.0, 2.5, 2.5, 3.0, 2.5, 2.5, 2.5, 3.0, 4.0, 5.0, 2.5, 3.0, 2.5, 5.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.5, 2.5, 2.5, 1.5, 1.5, 2.5, '  Score : 3.0.', 2.5, 3.0, 4.5, '  Score : 1.5.', 1.5, 4.0, 3.5, 2.0, 2.5, 4.0, 2.5, 3.0, 2.5, 3.0, '  Score : 2.5.', 2.5, 5.0, 2.5, 4.0, 2.5, 4.5, 2.5, 4.0, 3.0, 2.5, 3.0, 2.0, 2.5, 3.0, 2.5, 3.0, 3.0, 3.0, '  Score : 3.0.', 3.5, 2.0, 2.5, 2.5, 4.0, 5.0, 2.5, 3.0, 3.0, 2.0, 1.0, 2.5, 2.5, 4.5, '  Score : 3.0.', 3.0, 2.5, 3.0, 2.5, 2.5, 3.0, 5.0, 2.5, 2.5, 3.0, 2.5, 3.0, 2.5, 4.0, 2.5, 2.5, 2.5, 3.0, 2.5, 4.0, 4.0, 3.5, 4.0, 2.5, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 3.0, 4.5, 5.0, 1.5, 2.5, 3.0, 3.0, 3.0, 3.0, 2.5, 3.5, 5.0, 3.0, 2.5, 3.0, 2.5, 5.0, 3.0, 3.0, 3.5, 5.0, 4.0, 3.0, '  Score : 3.0,', 3.0, 5.0, 3.0, 4.0, 3.0, 2.5, 2.5, 2.5, 5.0, 2.5, 2.5, 4.5, 3.0, 3.0, 5.0, 1.5, 3.0, 5.0, 4.0, 2.5, 2.5, 3.0, 2.0, 3.0, 2.5, 4.0, 5.0, 4.0, 4.0, 5.0, 2.5, 3.0, 4.5, 3.0, 2.5, 2.0, 2.5, 2.5, 5.0, 5.0, 2.5, 2.5, 3.0, 3.0, 3.0, 3.0, 2.5, 3.0, '  Score : 2.5.', 4.0, 3.0, 2.5, 2.5, 2.0, 4.0, 3.0, 1.5, 3.0, 5.0, 2.5, 2.5, '  Score : 1.0.', 3.0, 5.0, 5.0, 2.5, 2.5, 3.0, 5.0, 4.5, 3.0, 3.0, 2.5, 4.0, 4.0, 1.5, 4.0, 3.0, 2.5, 5.0, 2.5, 2.5, 2.5, 4.0, 2.5, 4.5, 4.0, 2.5, 2.5, 2.5, 4.0, 3.0, 4.5, 2.5, 3.0, 3.0, 3.0, 2.5, '  Score : 3.0.', 2.5, 4.0, '  Score : 2.5;', 2.5, 3.0, 3.0, 2.5, 4.0, 3.0, 3.0, 3.0, 2.5, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.5, 4.5, 2.0, 2.5, 2.5, 2.5, 2.0, 4.5, 4.0, 2.5, 4.0, 3.0, 1.5, 3.0, 2.5, 2.5, 2.5, 5.0, 2.5, 2.5, 3.5, 2.5, 4.0, 4.0, 5.0, 2.5, 4.5, 2.5, 4.5, 5.0, 2.5, 1.5, 2.5, 3.0, 1.0, 2.5, 2.5, 2.5, 3.0, 2.5, 4.0, 2.5, 3.0, 1.0, 3.0, 3.0, 4.0, 2.5, 3.0, 3.0, 2.5, 4.5, 3.0, 3.0, 5.0, 2.5, 5.0, 4.0, 2.5, 3.0, 4.0, '  Score : 3.0.', 3.0, 3.5, 4.0, 3.0, 2.5, 2.5, 4.0, 3.0, 2.5, 2.5, 3.0, 5.0, 1.5, 2.5, 3.0, 3.0, 3.0, 2.5, '  Score : 2.5.', 2.5, 5.0, 2.5, 3.0, 4.0, 4.0, '  Score : 4.0.', 3.0, 4.0]\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(outputs_finetuned)):\n",
        "    if type(outputs_finetuned[i]) != float:\n",
        "        print(\"Fine Tuned : \", i, \" - \", outputs_finetuned[i])\n",
        "\n",
        "    if type(outputs_model[i]) != float:\n",
        "        print(\"Fine Tuned : \", i, \" - \", outputs_model[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean the outputs using regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "P0opk0of3b0Z"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "pattern = r\"Score\\s*:\\s*([\\d.]+)\\b\"\n",
        "outputs_finetuned_cleaned = []\n",
        "outputs_model_cleaned = []\n",
        "\n",
        "for string in outputs_finetuned:\n",
        "  if type(string) != float:\n",
        "    match = re.search(pattern, string)\n",
        "    if match:\n",
        "        score = float(match.group(1))\n",
        "        outputs_finetuned_cleaned.append(score)\n",
        "    else:\n",
        "      outputs_finetuned_cleaned.append(string)\n",
        "  else:\n",
        "    outputs_finetuned_cleaned.append(string)\n",
        "\n",
        "for string in outputs_model:\n",
        "  if type(string) != float:\n",
        "    match = re.search(pattern, string)\n",
        "    if match:\n",
        "        score = float(match.group(1))\n",
        "        outputs_model_cleaned.append(score)\n",
        "    else:\n",
        "      outputs_model_cleaned.append(string)\n",
        "  else:\n",
        "    outputs_model_cleaned.append(string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save the outputs to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-96aicgRtndW"
      },
      "outputs": [],
      "source": [
        "# Example NumPy array\n",
        "aoarr = np.array(actual_outputs)\n",
        "finetuned_output_arr = np.array(outputs_finetuned_cleaned)\n",
        "model_output_arr = np.array(outputs_model_cleaned)\n",
        "\n",
        "\n",
        "# Save the array to disk\n",
        "np.save('./actual_outputs.npy', aoarr)\n",
        "np.save('./outputs_finetuned_cleaned.npy', finetuned_output_arr)\n",
        "np.save('./outputs_model2_cleaned.npy', model_output_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCNhDp4BDsnL"
      },
      "source": [
        "# Sequence classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "73fb8f1978064e6bb30f519ac27b36e1",
            "46a5eeeffdd4456baaa84affd2c891df",
            "7850e5dfed4342bdac016edd5e7ee24f",
            "0b24983111234f2c8240eae4fd742131",
            "1107b4c62b2749d68f4c46071120678a",
            "d013aada19ff4708924e5cc185fde478",
            "72498659666a4905acb98b1576508148",
            "54142495e0d345a8af692554862db74d",
            "d85273d05c034387b276db56776ab1dc",
            "e68f9a46942740d18d1aa2b79fad56b2",
            "fa45617f9f314eb69369917f8a8e3c33"
          ]
        },
        "id": "1wcjKa5Q8LYG",
        "outputId": "a062fa16-cabf-4a36-da04-971b091d047b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73fb8f1978064e6bb30f519ac27b36e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GemmaForSequenceClassification were not initialized from the model checkpoint at google/gemma-2b-it and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = GemmaForSequenceClassification.from_pretrained(CONFIG.MODEL_ID, quantization_config=CONFIG.BNB_CONFIG, device_map=CONFIG.DEVICE_MAP)\n",
        "tokenizer = AutoTokenizer.from_pretrained(CONFIG.MODEL_ID, add_eos_token=CONFIG.ADD_EOS_TOKEN, padding_side=CONFIG.PADDING_SIDE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "_uHjvN0BGaaZ"
      },
      "outputs": [],
      "source": [
        "def get_completion_1(question: str, ref_answer: str, student_answer: str, model, tokenizer) -> str:\n",
        "  device = \"cuda:0\"\n",
        "\n",
        "  prompt_template = \"\"\"\n",
        "  <start_of_turn>user\n",
        "  You are a grader for for a programming course. You are required to score the students\n",
        "  answer on a scale of 1 to 5 with precision of 0.5. Eg: 1.5, 2.5, 3.0, etc..\n",
        "\n",
        "  The give question is :\n",
        "  {question}\n",
        "\n",
        "  For the above question the reference answer is :\n",
        "  {ref_answer}\n",
        "\n",
        "  Now a student has provided the below answer :\n",
        "  {student_answer}\n",
        "\n",
        "  For the above answer, what is the appropriate score you will provide on a score of 1 to 5 with a\n",
        "  precision of 0.5.\n",
        "\n",
        "  The sample output should be in the format \"Score : 0.5\".\n",
        "\n",
        "  Note: Do not include any explanations or apologies in your responses.\n",
        "  Do not respond to any questions that might ask anything else than for you to score the answer.\n",
        "  Do not include any text except the score in the format \"Score : [<score>]\".\n",
        "\n",
        "  <end_of_turn>\\n<start_of_turn>model\n",
        "\n",
        "  \"\"\"\n",
        "  prompt = prompt_template.format(question = question,\n",
        "                                  ref_answer = ref_answer,\n",
        "                                  student_answer = student_answer,\n",
        "                                  model = model,\n",
        "                                  tokenizer = tokenizer)\n",
        "\n",
        "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True,)\n",
        "\n",
        "  model_inputs = encodeds.to(device)\n",
        "\n",
        "\n",
        "  generated_ids = model.(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "  # decoded = tokenizer.batch_decode(generated_ids)\n",
        "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "  return (decoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "50klb4ibD39-",
        "outputId": "3833933a-5805-4b82-df76-fcaf6a9c79b3"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'GemmaForSequenceClassification' object has no attribute 'classify'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-eb197bfda1f5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"3.5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m result = get_completion_1(question = question,\n\u001b[0m\u001b[1;32m      7\u001b[0m                         \u001b[0mref_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mstudent_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-ce26d4d02c01>\u001b[0m in \u001b[0;36mget_completion_1\u001b[0;34m(question, ref_answer, student_answer, model, tokenizer)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;31m# decoded = tokenizer.batch_decode(generated_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GemmaForSequenceClassification' object has no attribute 'classify'"
          ]
        }
      ],
      "source": [
        "question = \"What is the role of a prototype program in problem solving?\"\n",
        "ref_answer = \"To simulate the behaviour of portions of the desired software product.\"\n",
        "student_answer = \"High risk problems are address in the prototype program to make sure that the program is feasible.  A prototype may also be used to show a company that the software can be possibly programmed.  \"\n",
        "score = \"3.5\"\n",
        "\n",
        "result = get_completion_1(question = question,\n",
        "                        ref_answer = ref_answer,\n",
        "                        student_answer = student_answer,\n",
        "                        model = model,\n",
        "                        tokenizer = tokenizer)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xDzQy4tD8u3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06827a8d15f64d79ba98c30eecfa5d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06c6da7350904d8c9685430457a5547b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b209933a5d94ff9a92c2f944a4420e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b24983111234f2c8240eae4fd742131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e68f9a46942740d18d1aa2b79fad56b2",
            "placeholder": "​",
            "style": "IPY_MODEL_fa45617f9f314eb69369917f8a8e3c33",
            "value": " 2/2 [00:05&lt;00:00,  2.18s/it]"
          }
        },
        "1107b4c62b2749d68f4c46071120678a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149e08f1c69c49ba98535010d8470894": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17fbe663c5264c5ab046d3d79f7db45e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19cf4616f5f547d9861d98f7350034ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7a15f160a4c44babe366d740d198cb4",
              "IPY_MODEL_7e639766ac784badbf5b66d87eab9b82",
              "IPY_MODEL_d5ef7839648048b0b30755a289d313e5"
            ],
            "layout": "IPY_MODEL_3718bbeec3544a8aab6103ac0c0f3247"
          }
        },
        "1f92ea54c3a943daae5deee576d822e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265dffeb6f2e46cbab16d7ce50ff730b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2683bb7995cd41b6904209424e706c38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ce0db2bd6c45c1818ed285ccc50dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea14849cf2d447290ba7097b2568845",
            "placeholder": "​",
            "style": "IPY_MODEL_ebcb2b1cb1ab4d198e2c9896ddf93e39",
            "value": "Map: 100%"
          }
        },
        "2e6c5c39aaf84976a1247e31e83c4999": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3718bbeec3544a8aab6103ac0c0f3247": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b39db11af347dba47b8802cba3c11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f2b166470db4eeabac98ad7db8853b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_932855a1c23147fc823b5c65bff1acd7",
              "IPY_MODEL_6199538a818741e58e5fb557e41b5893",
              "IPY_MODEL_b2836276208a4629b61427394e93839e"
            ],
            "layout": "IPY_MODEL_149e08f1c69c49ba98535010d8470894"
          }
        },
        "46a5eeeffdd4456baaa84affd2c891df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d013aada19ff4708924e5cc185fde478",
            "placeholder": "​",
            "style": "IPY_MODEL_72498659666a4905acb98b1576508148",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4eaa2693fd6a487798f572843b2c2ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6892a60bbc74bb6b1309e63058e4924",
              "IPY_MODEL_95e945ef83d94a64b4726e2e2fae10a9",
              "IPY_MODEL_b149923fa8e34e37bb4e7d0f147804ca"
            ],
            "layout": "IPY_MODEL_17fbe663c5264c5ab046d3d79f7db45e"
          }
        },
        "527db0079b5240c686acee09329d5f84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54142495e0d345a8af692554862db74d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60687234ffb4449fbaf589d35f2120b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6199538a818741e58e5fb557e41b5893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9911003026d9451681d52869e8af5320",
            "max": 4735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c25bd12e7a8948c0ab916e9efda39ad1",
            "value": 4735
          }
        },
        "72498659666a4905acb98b1576508148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73fb8f1978064e6bb30f519ac27b36e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46a5eeeffdd4456baaa84affd2c891df",
              "IPY_MODEL_7850e5dfed4342bdac016edd5e7ee24f",
              "IPY_MODEL_0b24983111234f2c8240eae4fd742131"
            ],
            "layout": "IPY_MODEL_1107b4c62b2749d68f4c46071120678a"
          }
        },
        "741bb1694ea14ad78659b621e0f096ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265dffeb6f2e46cbab16d7ce50ff730b",
            "placeholder": "​",
            "style": "IPY_MODEL_861779d429534021952d339c814b483b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7850e5dfed4342bdac016edd5e7ee24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54142495e0d345a8af692554862db74d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d85273d05c034387b276db56776ab1dc",
            "value": 2
          }
        },
        "7e639766ac784badbf5b66d87eab9b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c59eeca241444813846b4c7e14216495",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad26c5c13ecf46628f26856edb69c93b",
            "value": 2
          }
        },
        "7f5b4e542cb44d6db12a5a0ed4f3e920": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "861779d429534021952d339c814b483b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88330c55ddd04032b4640787125a2021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932855a1c23147fc823b5c65bff1acd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34341b354274c55a813d8f043144124",
            "placeholder": "​",
            "style": "IPY_MODEL_ebee9b8f3aaf4eefa1f3b9be0013bfe4",
            "value": "Map: 100%"
          }
        },
        "935d8e7e02444b539464c98d2d8bc534": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9361e7032a374077abecdb285bebc64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e945ef83d94a64b4726e2e2fae10a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_527db0079b5240c686acee09329d5f84",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06827a8d15f64d79ba98c30eecfa5d2a",
            "value": 2
          }
        },
        "9911003026d9451681d52869e8af5320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a9dabcbcde43659ab648d4bde6fe59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3dd105380ae4c7399498f026234190e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_741bb1694ea14ad78659b621e0f096ac",
              "IPY_MODEL_c2c036802e164c198368244d386835e3",
              "IPY_MODEL_c06e2e7ac69e4404bfc8bd8f681a1bba"
            ],
            "layout": "IPY_MODEL_0b209933a5d94ff9a92c2f944a4420e2"
          }
        },
        "a7a15f160a4c44babe366d740d198cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e5c0b616004bc39bb34550854d8ff3",
            "placeholder": "​",
            "style": "IPY_MODEL_935d8e7e02444b539464c98d2d8bc534",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ad26c5c13ecf46628f26856edb69c93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b149923fa8e34e37bb4e7d0f147804ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88330c55ddd04032b4640787125a2021",
            "placeholder": "​",
            "style": "IPY_MODEL_c46dc5f214b94e0b9e0e3e13a953217e",
            "value": " 2/2 [00:04&lt;00:00,  1.92s/it]"
          }
        },
        "b2836276208a4629b61427394e93839e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e6c5c39aaf84976a1247e31e83c4999",
            "placeholder": "​",
            "style": "IPY_MODEL_a2a9dabcbcde43659ab648d4bde6fe59",
            "value": " 4735/4735 [00:00&lt;00:00, 6789.08 examples/s]"
          }
        },
        "b34341b354274c55a813d8f043144124": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a8cf5b6f2043bfadd4a1aeef11f084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd173dc720a742488fe364d525da4d8c",
            "placeholder": "​",
            "style": "IPY_MODEL_37b39db11af347dba47b8802cba3c11d",
            "value": " 4735/4735 [00:00&lt;00:00, 5470.56 examples/s]"
          }
        },
        "b6892a60bbc74bb6b1309e63058e4924": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9eb0b3e2dd749e1927be4d5b5f1cb38",
            "placeholder": "​",
            "style": "IPY_MODEL_9361e7032a374077abecdb285bebc64d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bb4348e548a64ad785e2da9f4c0fbff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29ce0db2bd6c45c1818ed285ccc50dea",
              "IPY_MODEL_c9c71f646f854e58ae1828a69ddf79c8",
              "IPY_MODEL_b4a8cf5b6f2043bfadd4a1aeef11f084"
            ],
            "layout": "IPY_MODEL_1f92ea54c3a943daae5deee576d822e4"
          }
        },
        "bcb6f5d5775841069c63f4220e327db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06e2e7ac69e4404bfc8bd8f681a1bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c10490f0d26e4764bc92d0b5627b2d98",
            "placeholder": "​",
            "style": "IPY_MODEL_ed4b4c1d375e42809e9b2416b6688e60",
            "value": " 2/2 [00:03&lt;00:00,  1.62s/it]"
          }
        },
        "c10490f0d26e4764bc92d0b5627b2d98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c25bd12e7a8948c0ab916e9efda39ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2c036802e164c198368244d386835e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60687234ffb4449fbaf589d35f2120b8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f94d411368a147cd8753b8d3e0c47d1d",
            "value": 2
          }
        },
        "c46dc5f214b94e0b9e0e3e13a953217e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c59eeca241444813846b4c7e14216495": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c71f646f854e58ae1828a69ddf79c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2683bb7995cd41b6904209424e706c38",
            "max": 4735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f5b4e542cb44d6db12a5a0ed4f3e920",
            "value": 4735
          }
        },
        "c9eb0b3e2dd749e1927be4d5b5f1cb38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d013aada19ff4708924e5cc185fde478": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ef7839648048b0b30755a289d313e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c6da7350904d8c9685430457a5547b",
            "placeholder": "​",
            "style": "IPY_MODEL_bcb6f5d5775841069c63f4220e327db4",
            "value": " 2/2 [00:04&lt;00:00,  2.14s/it]"
          }
        },
        "d85273d05c034387b276db56776ab1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9e5c0b616004bc39bb34550854d8ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea14849cf2d447290ba7097b2568845": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68f9a46942740d18d1aa2b79fad56b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebcb2b1cb1ab4d198e2c9896ddf93e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebee9b8f3aaf4eefa1f3b9be0013bfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed4b4c1d375e42809e9b2416b6688e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f94d411368a147cd8753b8d3e0c47d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa45617f9f314eb69369917f8a8e3c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd173dc720a742488fe364d525da4d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
